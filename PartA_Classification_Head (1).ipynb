{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fj41POPjrtzA",
   "metadata": {
    "id": "fj41POPjrtzA"
   },
   "source": [
    "# <font color = 'indianred'> **1. Setting up the Environment** </font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d54de23-80e9-4e1b-816c-6f6916c92836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/62.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/16.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m10.0/16.6 MB\u001b[0m \u001b[31m299.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m304.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m144.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.3.4 which is incompatible.\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.4 which is incompatible.\n",
      "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.4 which is incompatible.\n",
      "cupy-cuda12x 13.3.0 requires numpy<2.3,>=1.22, but you have numpy 2.3.4 which is incompatible.\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.4 which is incompatible.\n",
      "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m121.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m506.8/506.8 kB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m423.1/423.1 kB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pylibcudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\n",
      "cudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# If in Colab, then import the drive module from google.colab\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "  !pip install numpy -U -qq\n",
    "  !pip install transformers evaluate wandb datasets accelerate trl peft bitsandbytes -U -qq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tJxYZaIoDezg",
   "metadata": {
    "id": "tJxYZaIoDezg"
   },
   "source": [
    " <Font size = 5 color = 'indianred'>**Restart the session before moving onto next cell**\n",
    "> Runtime- Restart Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WrXclsSX0PO7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -Uqq torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1Kcz9H4QsW6_",
   "metadata": {
    "id": "1Kcz9H4QsW6_"
   },
   "source": [
    "<font color = 'indianred'> *Load Libraries* </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yC6lJrxYvxeF",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard data science librraies for data handling and v isualization\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import re\n",
    "import gc\n",
    "import time\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import multilabel_confusion_matrix, precision_score, recall_score, f1_score\n",
    "import joblib\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import ast\n",
    "\n",
    "\n",
    "# New libraries introduced in this notebook\n",
    "import evaluate\n",
    "from datasets import load_dataset, DatasetDict, Dataset, ClassLabel\n",
    "from transformers import (\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    set_seed,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoConfig,\n",
    "    pipeline,\n",
    "    BitsAndBytesConfig,\n",
    ")\n",
    "\n",
    "from trl import SFTTrainer\n",
    "from peft import (\n",
    "    TaskType,\n",
    "    LoraConfig,\n",
    "    prepare_model_for_kbit_training,\n",
    "    get_peft_model,\n",
    "    AutoPeftModelForSequenceClassification,\n",
    "    PeftConfig\n",
    ")\n",
    "import wandb\n",
    "from google.colab import userdata\n",
    "from huggingface_hub import login, HfApi, create_repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lVxoZA87sPPe",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_api_key = userdata.get('WANDB_API_KEY')\n",
    "hf_token = userdata.get('HF_Token')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yhnu-cursbNM",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully logged in to Hugging Face!\n"
     ]
    }
   ],
   "source": [
    "if hf_token:\n",
    "    # Log in to Hugging Face\n",
    "    login(token=hf_token)\n",
    "    print(\"Successfully logged in to Hugging Face!\")\n",
    "else:\n",
    "    print(\"Hugging Face token not found in notebook secrets.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4kvSqsTVs0Ze",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
      "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mronchaudhuri29\u001b[0m (\u001b[33mronchaudhuri29-the-university-of-texas-at-dallas\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully logged in to WANDB!\n"
     ]
    }
   ],
   "source": [
    "if wandb_api_key:\n",
    "  wandb.login(key=wandb_api_key)\n",
    "  print(\"Successfully logged in to WANDB!\")\n",
    "else:\n",
    "    print(\"WANDB key not found in notebook secrets.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b906904c-8f24-4de0-8e07-720863e8cd99",
   "metadata": {
    "id": "b906904c-8f24-4de0-8e07-720863e8cd99"
   },
   "source": [
    "# <font color = 'indianred'> **2. Load Data set**\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0TbK1W8CtB9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# Determine the storage location based on the execution environment\n",
    "# If running on Google Colab, use Google Drive as storage\n",
    "# CHANGE FOLDERS TO WHERE YOU WANT TO SAVE DATA AND MODELS\n",
    "\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    from google.colab import drive  # Import Google Drive mounting utility\n",
    "    drive.mount('/content/drive')  # Mount Google Drive\n",
    "\n",
    "    # Set base folder path for storing data on Google Drive\n",
    "    base_folder= Path('/content/drive/MyDrive/data')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SGGMBhdhHMnK",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1JpTLLoCvuAY",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (2029, 9)\n",
      "Test shape: (10, 8)\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 2029,\n  \"fields\": [\n    {\n      \"column\": \"row_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 585,\n        \"min\": 0,\n        \"max\": 2028,\n        \"num_unique_values\": 2029,\n        \"samples\": [\n          1356,\n          984,\n          859\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"body\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1869,\n        \"samples\": [\n          \"Everything explain in 90 seconds https://www.youtube.com/watch?v=GIEwd837k5s\",\n          \"How do you go about spoofing without getting caught and banned?\",\n          \"...So you're telling me that I could go graverobbing and make 1.4k a pop?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rule\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"No legal advice: Do not offer or request legal advice.\",\n          \"No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"subreddit\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"Android\",\n          \"spacex\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"positive_example_1\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 458,\n        \"samples\": [\n          \"Yes, but she's reported me before. FBI can just subpena. It was also reported by the same person twice. So the FBI will definitely subpoena it. \\n\\nI just need to find people to snitch on so I can get out of it. \",\n          \" she is  for free  therein  masturbate  http://annon.link/qiit\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"positive_example_2\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 461,\n        \"samples\": [\n          \"This study is propaganda.  Yes, background checks are required in every state.  But this study is saying, \\\"45 states don't require background checks!\\\"  And that is only true in the sense that, the states themselves *don't need to* require background checks, since Federal law already does require them, and applies even to transactions that occur wholly within a single state.  It's just straight dishonest, afaict.\",\n          \"He signed NDAA. Treason. Any jury of people aware of constitutional law would convict him.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"negative_example_1\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 489,\n        \"samples\": [\n          \"SD [Stream SD Mobile Supported Channel 2 EN](http://gern.co/content/click-here-watch-uefa-champions-league-live-streaming-link-online-free-0)\\n\\n\\nHD\\n\\n\\nDirect to Video streamSD [Stream SD Mobile Supported Channel 2 EN](http://gern.co/content/click-here-watch-uefa-champions-league-live-streaming-link-online-free-0)\\n\\n\\nHD\\n\\n\\nDirect to Video stream\",\n          \"[WEB ONLY] [AdBlock OK] SD - ENGLISH [Stream #1](http://www.goindexsport.com/AIK---Bala.html) \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"negative_example_2\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 493,\n        \"samples\": [\n          \"[Mobile Utilities](https://play.google.com/store/apps/details?id=andromart.mobileutilities) would probably contain a few things that you (and most students around) would find extremely useful. \",\n          \"We will be launching our stable not Niantic server straining Pokemon finder on Monday....will look like what most are used to..stay tuned or on [Twitter](https://twitter.com/pokefindernow)\\nOn with the fun again! [Pokefinder](www.pokefindernow.com)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rule_violation\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "train_df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-6ca1cb5d-a4fd-415d-8ccc-69bdab75b860\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>body</th>\n",
       "      <th>rule</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>positive_example_1</th>\n",
       "      <th>positive_example_2</th>\n",
       "      <th>negative_example_1</th>\n",
       "      <th>negative_example_2</th>\n",
       "      <th>rule_violation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Banks don't want you to know this! Click here ...</td>\n",
       "      <td>No Advertising: Spam, referral links, unsolici...</td>\n",
       "      <td>Futurology</td>\n",
       "      <td>If you could tell your younger self something ...</td>\n",
       "      <td>hunt for lady for jack off in neighbourhood ht...</td>\n",
       "      <td>Watch Golden Globe Awards 2017 Live Online in ...</td>\n",
       "      <td>DOUBLE CEE x BANDS EPPS - \"BIRDS\"\\n\\nDOWNLOAD/...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>SD Stream [ ENG Link 1] (http://www.sportsstre...</td>\n",
       "      <td>No Advertising: Spam, referral links, unsolici...</td>\n",
       "      <td>soccerstreams</td>\n",
       "      <td>[I wanna kiss you all over! Stunning!](http://...</td>\n",
       "      <td>LOLGA.COM is One of the First Professional Onl...</td>\n",
       "      <td>#Rapper \\nüö®Straight Outta Cross Keys SC üö®YouTu...</td>\n",
       "      <td>[15 Amazing Hidden Features Of Google Search Y...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Lol. Try appealing the ban and say you won't d...</td>\n",
       "      <td>No legal advice: Do not offer or request legal...</td>\n",
       "      <td>pcmasterrace</td>\n",
       "      <td>Don't break up with him or call the cops.  If ...</td>\n",
       "      <td>It'll be dismissed: https://en.wikipedia.org/w...</td>\n",
       "      <td>Where is there a site that still works where y...</td>\n",
       "      <td>Because this statement of his is true. It isn'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>she will come your home open her legs with  an...</td>\n",
       "      <td>No Advertising: Spam, referral links, unsolici...</td>\n",
       "      <td>sex</td>\n",
       "      <td>Selling Tyrande codes for 3‚Ç¨ to paypal. PM. \\n...</td>\n",
       "      <td>tight pussy watch for your cock get her at thi...</td>\n",
       "      <td>NSFW(obviously) http://spankbang.com/iy3u/vide...</td>\n",
       "      <td>Good News ::Download WhatsApp 2.16.230 APK for...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>code free tyrande ---&gt;&gt;&gt; [Imgur](http://i.imgu...</td>\n",
       "      <td>No Advertising: Spam, referral links, unsolici...</td>\n",
       "      <td>hearthstone</td>\n",
       "      <td>wow!! amazing reminds me of the old days.Well...</td>\n",
       "      <td>seek for lady for sex in around http://p77.pl/...</td>\n",
       "      <td>must be watch movie https://sites.google.com/s...</td>\n",
       "      <td>We're streaming Pokemon Veitnamese Crystal RIG...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6ca1cb5d-a4fd-415d-8ccc-69bdab75b860')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-6ca1cb5d-a4fd-415d-8ccc-69bdab75b860 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-6ca1cb5d-a4fd-415d-8ccc-69bdab75b860');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-ae7f40ec-082d-49c5-bebb-741987784ace\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ae7f40ec-082d-49c5-bebb-741987784ace')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-ae7f40ec-082d-49c5-bebb-741987784ace button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   row_id                                               body  \\\n",
       "0       0  Banks don't want you to know this! Click here ...   \n",
       "1       1  SD Stream [ ENG Link 1] (http://www.sportsstre...   \n",
       "2       2  Lol. Try appealing the ban and say you won't d...   \n",
       "3       3  she will come your home open her legs with  an...   \n",
       "4       4  code free tyrande --->>> [Imgur](http://i.imgu...   \n",
       "\n",
       "                                                rule      subreddit  \\\n",
       "0  No Advertising: Spam, referral links, unsolici...     Futurology   \n",
       "1  No Advertising: Spam, referral links, unsolici...  soccerstreams   \n",
       "2  No legal advice: Do not offer or request legal...   pcmasterrace   \n",
       "3  No Advertising: Spam, referral links, unsolici...            sex   \n",
       "4  No Advertising: Spam, referral links, unsolici...    hearthstone   \n",
       "\n",
       "                                  positive_example_1  \\\n",
       "0  If you could tell your younger self something ...   \n",
       "1  [I wanna kiss you all over! Stunning!](http://...   \n",
       "2  Don't break up with him or call the cops.  If ...   \n",
       "3  Selling Tyrande codes for 3‚Ç¨ to paypal. PM. \\n...   \n",
       "4   wow!! amazing reminds me of the old days.Well...   \n",
       "\n",
       "                                  positive_example_2  \\\n",
       "0  hunt for lady for jack off in neighbourhood ht...   \n",
       "1  LOLGA.COM is One of the First Professional Onl...   \n",
       "2  It'll be dismissed: https://en.wikipedia.org/w...   \n",
       "3  tight pussy watch for your cock get her at thi...   \n",
       "4  seek for lady for sex in around http://p77.pl/...   \n",
       "\n",
       "                                  negative_example_1  \\\n",
       "0  Watch Golden Globe Awards 2017 Live Online in ...   \n",
       "1  #Rapper \\nüö®Straight Outta Cross Keys SC üö®YouTu...   \n",
       "2  Where is there a site that still works where y...   \n",
       "3  NSFW(obviously) http://spankbang.com/iy3u/vide...   \n",
       "4  must be watch movie https://sites.google.com/s...   \n",
       "\n",
       "                                  negative_example_2  rule_violation  \n",
       "0  DOUBLE CEE x BANDS EPPS - \"BIRDS\"\\n\\nDOWNLOAD/...               0  \n",
       "1  [15 Amazing Hidden Features Of Google Search Y...               0  \n",
       "2  Because this statement of his is true. It isn'...               1  \n",
       "3  Good News ::Download WhatsApp 2.16.230 APK for...               1  \n",
       "4  We're streaming Pokemon Veitnamese Crystal RIG...               1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_folder = base_folder/'datasets'\n",
    "import pandas as pd\n",
    "\n",
    "train_path = data_folder / 'train.csv'\n",
    "test_path  = data_folder / 'test.csv'\n",
    "sub_path   = data_folder/'sample_submission.csv'\n",
    "\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df  = pd.read_csv(test_path)\n",
    "sample_sub = pd.read_csv(sub_path)\n",
    "\n",
    "print(\"Train shape:\", train_df.shape)\n",
    "print(\"Test shape:\", test_df.shape)\n",
    "train_df.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "M8vtN_NL7R7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sample combined text:\n",
      "Comment: Banks don't want you to know this! Click here to know more! | Subreddit: Futurology | Rule: No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed. | Positive ex1: If you could tell your younger self something different about sex, what would that be?  i AM IN A CONTEST TO WIN FUNDING FOR MY SEX POSITIVE FILM: VOTE HERE:  http://sheknows.offerpop.com/campaign/813112/entry/v144417 | Positive ex2: hunt for lady for jack off in neighbourhood h\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- Helper: safe get + stringify + prefix label ---\n",
    "def _fmt(prefix, val):\n",
    "    if pd.isna(val) or (isinstance(val, str) and not val.strip()):\n",
    "        return \"\"\n",
    "    s = str(val).replace(\"\\n\", \" \").strip()\n",
    "    return f\"{prefix}{s} | \"\n",
    "\n",
    "# Columns to combine (use only if they exist)\n",
    "CTX_COLUMNS = [\n",
    "    (\"Comment: \", \"body\"),\n",
    "    (\"Subreddit: \", \"subreddit\"),\n",
    "    (\"Rule: \", \"rule\"),\n",
    "    (\"Positive ex1: \", \"positive_example_1\"),\n",
    "    (\"Positive ex2: \", \"positive_example_2\"),\n",
    "    (\"Negative ex1: \", \"negative_example_1\"),\n",
    "    (\"Negative ex2: \", \"negative_example_2\"),\n",
    "]\n",
    "\n",
    "\n",
    "def combine_row(row):\n",
    "    parts = []\n",
    "    for prefix, col in CTX_COLUMNS:\n",
    "        if col in row:\n",
    "            parts.append(_fmt(prefix, row[col]))\n",
    "    return \"\".join(parts) or \"Comment: \"\n",
    "\n",
    "# --- Build combined text ---\n",
    "train_df[\"text\"] = train_df.apply(combine_row, axis=1)\n",
    "test_df[\"text\"]  = test_df.apply(combine_row, axis=1)\n",
    "\n",
    "# --- Map target & ids ---\n",
    "train_df = train_df.rename(columns={\"rule_violation\": \"label\"})\n",
    "\n",
    "# --- Ensure binary labels ---\n",
    "train_df[\"label\"] = pd.to_numeric(train_df[\"label\"], errors=\"raise\").astype(int)\n",
    "unique_labels = set(train_df[\"label\"].unique())\n",
    "assert unique_labels <= {0, 1}, f\"Expected binary labels 0/1, got {unique_labels}\"\n",
    "\n",
    "print(\" Sample combined text:\")\n",
    "print(train_df[\"text\"].iloc[0][:500])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bJnCcArQJ0Vd",
   "metadata": {
    "id": "bJnCcArQJ0Vd"
   },
   "source": [
    "# <font color = 'indianred'> **3. Accessing and Manuplating Splits**</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "F4Lpc6ItMyUi",
   "metadata": {
    "id": "F4Lpc6ItMyUi"
   },
   "source": [
    "<font color = 'indianred'>*Create futher subdivions of the splits*</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8YTYKAMhaV",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 1623\n",
      "}) Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 406\n",
      "}) Dataset({\n",
      "    features: ['row_id', 'text'],\n",
      "    num_rows: 10\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# ---- Part A: train/val split and HF datasets ----\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "\n",
    "# Split TRAIN ‚Üí train/val (stratified by your binary label)\n",
    "train_split, val_split = train_test_split(\n",
    "    train_df[[\"row_id\", \"text\", \"label\"]],\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=train_df[\"label\"]\n",
    ")\n",
    "\n",
    "# Convert to HF datasets (keep only text+label for training)\n",
    "train_ds = Dataset.from_pandas(train_split[[\"text\",\"label\"]].reset_index(drop=True))\n",
    "val_ds   = Dataset.from_pandas(val_split[[\"text\",\"label\"]].reset_index(drop=True))\n",
    "\n",
    "# Keep row_id for submission alignment on test\n",
    "test_ds  = Dataset.from_pandas(test_df[[\"row_id\",\"text\"]].reset_index(drop=True))\n",
    "\n",
    "print(train_ds, val_ds, test_ds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CY6NEjV6z7-i",
   "metadata": {
    "id": "CY6NEjV6z7-i"
   },
   "source": [
    "<font color = 'indianred'>*small subset for initial experimenttaion*</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KGiszuGZ17H3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_split = train_split.shuffle(seed = 42).select(range(2000))\n",
    "#val_split = val_split.shuffle(seed = 42).select(range(2000))\n",
    "#test_split = test_split.shuffle(seed = 42).select(range(2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IuEaHG3w150t",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_subset= DatasetDict(\n",
    "    {\"train\": train_split, \"valid\": val_split})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wnB3lHD0kPW-",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train:       row_id                                               text  label\n",
       "    1109    1109  Comment: Well first you have to figure out if ...      1\n",
       "    490      490  Comment: cheap cigarettes online Buy Discount ...      1\n",
       "    159      159  Comment: It's illegal, you can sue for pain an...      1\n",
       "    333      333  Comment: You should be fine. There have been c...      1\n",
       "    292      292  Comment: [Also Watch This Video - Olympics](ht...      0\n",
       "    ...      ...                                                ...    ...\n",
       "    467      467  Comment: #Rapper  üö®Straight Outta Cross Keys S...      0\n",
       "    1759    1759  Comment: I don't know the specifics of the que...      1\n",
       "    536      536  Comment: Selling Tyrande codes for 3‚Ç¨ to paypa...      1\n",
       "    677      677  Comment: If anyone is interested in donating 5...      0\n",
       "    1714    1714  Comment: look that pussy will  and be in on co...      1\n",
       "    \n",
       "    [1623 rows x 3 columns]\n",
       "    valid:       row_id                                               text  label\n",
       "    1962    1962  Comment: Talk about timeglass shape, WOW https...      0\n",
       "    1583    1583  Comment: That's called conspiracy to manslaugh...      0\n",
       "    423      423  Comment: Call of up every major bank and sign ...      0\n",
       "    70        70  Comment: Was willst du machen? Der Gesetzgeber...      1\n",
       "    465      465  Comment: You can't denied a benefit you were p...      1\n",
       "    ...      ...                                                ...    ...\n",
       "    731      731  Comment: hire private security to stay on the ...      0\n",
       "    1155    1155  Comment: If you or your BF took the photos it ...      1\n",
       "    424      424  Comment: I was just about to post this exact e...      1\n",
       "    1723    1723  Comment: H√¨nh ·∫£nh c·ª≠a g·ªó Huge t·∫°i D·ª± √Ån Gamuda...      1\n",
       "    329      329  Comment: Read the comment by /u/coolfusis abov...      1\n",
       "    \n",
       "    [406 rows x 3 columns]\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_val_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VgNj2At3kRSs",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_val_subset['train']['label'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b02690-50f7-49bf-aab4-85dbbb21d182",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T11:21:48.647438Z",
     "iopub.status.busy": "2022-12-20T11:21:48.646659Z",
     "iopub.status.idle": "2022-12-20T11:21:48.690232Z",
     "shell.execute_reply": "2022-12-20T11:21:48.689729Z",
     "shell.execute_reply.started": "2022-12-20T11:21:48.647414Z"
    },
    "id": "c7b02690-50f7-49bf-aab4-85dbbb21d182",
    "tags": []
   },
   "source": [
    "# <font color = 'indianred'>**4. Load pre-trained Tokenizer**</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hwPQKf5XvM7K",
   "metadata": {},
   "outputs": [],
   "source": [
    "def free_gpu_memory():\n",
    "    \"\"\"\n",
    "    Frees up GPU memory after CUDA out-of-memory error in Colab.\n",
    "\n",
    "    This function performs the following steps:\n",
    "    1. Deletes all PyTorch objects to clear references.\n",
    "    2. Calls garbage collection to remove unreferenced objects from memory.\n",
    "    3. Uses torch.cuda.empty_cache() to release cached GPU memory.\n",
    "    4. Waits for a moment to ensure memory is fully released.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Delete all torch tensors to free up memory\n",
    "        for obj in list(locals().values()):\n",
    "            if torch.is_tensor(obj):\n",
    "                del obj\n",
    "\n",
    "        # Collect garbage to release any remaining unused memory\n",
    "        gc.collect()\n",
    "\n",
    "        # Empty the CUDA cache to release GPU memory\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        # Adding a small delay to allow memory to be fully released\n",
    "        time.sleep(2)\n",
    "\n",
    "        print(\"GPU memory has been freed.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error while freeing GPU memory: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pPGuUj3bZUDU",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory has been freed.\n"
     ]
    }
   ],
   "source": [
    "free_gpu_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hzUiqZR6hI4o",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc3009986a7e431c8309a9f6cd84f538",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/46.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "421345c65b9c441091b864b273a65f2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9918f073e6847019c80b75bc434ff23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efc710fc9ff842759f88fa8eb0987b2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/636 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checkpoint = \"google/gemma-2-2b\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nUNlsheSG9lo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average: 279.842\n",
      "Max: 616\n"
     ]
    }
   ],
   "source": [
    "lengths = [len(tokenizer(text)[\"input_ids\"]) for text in train_df[\"text\"][:1000]]\n",
    "print(\"Average:\", sum(lengths)/len(lengths))\n",
    "print(\"Max:\", max(lengths))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4ce3b9-904f-42bd-9c3f-163328f47051",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T11:22:33.679936Z",
     "iopub.status.busy": "2022-12-20T11:22:33.679764Z",
     "iopub.status.idle": "2022-12-20T11:22:33.723366Z",
     "shell.execute_reply": "2022-12-20T11:22:33.722847Z",
     "shell.execute_reply.started": "2022-12-20T11:22:33.679918Z"
    },
    "id": "2b4ce3b9-904f-42bd-9c3f-163328f47051"
   },
   "source": [
    "#<font color = 'indianred'> **5. Create function for Tokenizer**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bAD2dsXhvAA",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_fn(batch):\n",
    "    return tokenizer(text = batch[\"text\"], truncation=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1VgditxyHqWd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d65fb4d07f54cd7b6095e81a529b652",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1623 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "184ba23caa69445db877c6738fc89ce0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/406 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6175203534e5416f9129ab7572846334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['label', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 1623\n",
      "    })\n",
      "    valid: Dataset({\n",
      "        features: ['label', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 406\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "# 1) Make sure splits are HF Datasets (not pandas DataFrames)\n",
    "def ensure_hf(ds, keep_cols):\n",
    "    # if it's already a Dataset, just select needed columns\n",
    "    from datasets import Dataset as HFDataset\n",
    "    if isinstance(ds, HFDataset):\n",
    "        return ds.select_columns(keep_cols)\n",
    "    else:\n",
    "        # assume pandas DataFrame\n",
    "        return Dataset.from_pandas(ds[keep_cols].reset_index(drop=True))\n",
    "\n",
    "train_hf = ensure_hf(train_split, [\"text\", \"label\"])\n",
    "val_hf   = ensure_hf(val_split,   [\"text\", \"label\"])\n",
    "\n",
    "# If you have test_split with row_id + text:\n",
    "try:\n",
    "    test_hf  = ensure_hf(test_ds,  [\"row_id\", \"text\"])\n",
    "except NameError:\n",
    "    test_hf = None\n",
    "\n",
    "# 2) Tokenize each split separately (remove raw text; on test also drop row_id before model)\n",
    "def tokenize_fn(batch):\n",
    "    return tokenizer(text=batch[\"text\"], truncation=True, max_length=512)\n",
    "\n",
    "tokenized_train = train_hf.map(tokenize_fn, batched=True, remove_columns=[\"text\"])\n",
    "tokenized_val   = val_hf.map(tokenize_fn,   batched=True, remove_columns=[\"text\"])\n",
    "\n",
    "if test_hf is not None:\n",
    "    test_ids = test_hf[\"row_id\"]                  # keep ids for submission\n",
    "    tokenized_test = test_hf.map(tokenize_fn, batched=True, remove_columns=[\"text\",\"row_id\"])\n",
    "\n",
    "# 3) Rebuild a proper DatasetDict and set PyTorch format\n",
    "tokenized_dataset = DatasetDict({\n",
    "    \"train\": tokenized_train,\n",
    "    \"valid\": tokenized_val\n",
    "})\n",
    "tokenized_dataset = tokenized_dataset.with_format(\"torch\")\n",
    "\n",
    "# (optional) keep tokenized_test separate for prediction\n",
    "if test_hf is not None:\n",
    "    tokenized_test = tokenized_test.with_format(\"torch\")\n",
    "\n",
    "print(tokenized_dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f09c889-c3fd-4b12-a544-0772594a3899",
   "metadata": {
    "id": "1f09c889-c3fd-4b12-a544-0772594a3899"
   },
   "source": [
    "<font color = 'indianred'> *Use map function to apply tokenization to all splits*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KF0UDACVqLh8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d2362b7fe2b4b72a690c8e2cd8bfa0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1623 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ac600a2c1fb494ba7dff52325a75dc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/406 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = (tokenized_dataset\n",
    "          .map(lambda x : {\"float_label\": x[\"label\"].to(torch.float)}, remove_columns=[\"label\"])\n",
    "          .rename_column(\"float_label\", \"label\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6Du_aOBBqYzA",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset['train']['label'][0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "O7-5sm2uBTN_",
   "metadata": {
    "id": "O7-5sm2uBTN_"
   },
   "source": [
    "#  <font color = 'indianred'> **6. Model Training**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2a39fc-6d87-43ca-8a6e-7129bd8214f1",
   "metadata": {
    "id": "cc2a39fc-6d87-43ca-8a6e-7129bd8214f1"
   },
   "source": [
    "##  <font color = 'indianred'> **6.1 Download pre-trained model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Uh43-6J8LWlS",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_appropriate_dtype():\n",
    "    if torch.cuda.is_available() and torch.cuda.get_device_capability(0) >= (8, 0):\n",
    "        return torch.bfloat16\n",
    "    return torch.float16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CBvrKgAeLZJV",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_data_type = get_appropriate_dtype()\n",
    "torch_data_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "g46jiz0vLSGk",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "  load_in_4bit=True,\n",
    "  bnb_4bit_quant_type=\"nf4\",\n",
    "  bnb_4bit_use_double_quant=True,\n",
    "  bnb_4bit_compute_dtype=torch_data_type,\n",
    "  bnb_4bit_quant_storage=torch_data_type,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58babf85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a185b438e1c346b59b1dce2e96a9acaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/818 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f02312f2d22472f8e90343cbf203beb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/24.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cdd00b211b248da931faa00880b09a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a428c6b5ec74ea78b4ca4617e16745f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52591a18da3f49c0bb03ec090b801ac2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/481M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c81ec1a2717349cfa2543a36dd50530a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7246325a36074aae9dbc9817de68247f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Gemma2ForSequenceClassification were not initialized from the model checkpoint at google/gemma-2-2b and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint,\n",
    "                                                           num_labels = 1,\n",
    "                                                           problem_type=\"single_label_classification\",\n",
    "                                                           quantization_config=bnb_config,\n",
    "                                                           dtype=torch_data_type,\n",
    "                                                           trust_remote_code=True,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jUaTwYBUwCcn",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gemma2ForSequenceClassification(\n",
       "  (model): Gemma2Model(\n",
       "    (embed_tokens): Embedding(256000, 2304, padding_idx=0)\n",
       "    (layers): ModuleList(\n",
       "      (0-25): 26 x Gemma2DecoderLayer(\n",
       "        (self_attn): Gemma2Attention(\n",
       "          (q_proj): Linear4bit(in_features=2304, out_features=2048, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=2304, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=2304, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=2048, out_features=2304, bias=False)\n",
       "        )\n",
       "        (mlp): Gemma2MLP(\n",
       "          (gate_proj): Linear4bit(in_features=2304, out_features=9216, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=2304, out_features=9216, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=9216, out_features=2304, bias=False)\n",
       "          (act_fn): GELUTanh()\n",
       "        )\n",
       "        (input_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
       "        (post_attention_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
       "        (pre_feedforward_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
       "        (post_feedforward_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
       "    (rotary_emb): Gemma2RotaryEmbedding()\n",
       "  )\n",
       "  (score): Linear(in_features=2304, out_features=1, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GS6SSVBUpFz1",
   "metadata": {
    "id": "GS6SSVBUpFz1"
   },
   "source": [
    "##  <font color = 'indianred'> **6.3 PEFT Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yIFhbC3wpLw6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 83,069,184 || all params: 2,697,413,376 || trainable%: 3.0796\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "# Typical Gemma targets\n",
    "lora_targets = [\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\",\"gate_proj\",\"up_proj\",\"down_proj\"]\n",
    "\n",
    "peft_cfg = LoraConfig(\n",
    "    r=64,\n",
    "    lora_alpha=128,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_CLS\",\n",
    "    target_modules=lora_targets,\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, peft_cfg)\n",
    "model.print_trainable_parameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ryMHJmlsNsv0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformers version: 4.57.1\n",
      "TrainingArguments from: transformers.training_args\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from transformers import TrainingArguments\n",
    "print(\"transformers version:\", transformers.__version__)\n",
    "print(\"TrainingArguments from:\", TrainingArguments.__module__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mkrx4u-QLnOx",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cc2ea0aca8947f79681979fedbd4316",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/1623 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "637a67ab81d24b3c9e483e20ce25700a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/406 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Value\n",
    "tokenized_dataset = tokenized_dataset.cast_column(\"label\", Value(\"float32\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "x-NgKhgeL9zW",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.use_cache = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52nDkWYvMBO9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import Trainer\n",
    "\n",
    "class BCETrainer(Trainer):\n",
    "    # accept the newer kwarg\n",
    "    def compute_loss(\n",
    "        self,\n",
    "        model,\n",
    "        inputs,\n",
    "        return_outputs: bool = False,\n",
    "        num_items_in_batch: int | None = None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        labels = inputs.pop(\"labels\").float()\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits.squeeze(-1)\n",
    "        loss = torch.nn.functional.binary_cross_entropy_with_logits(logits, labels)\n",
    "        return (loss, outputs) if return_outputs else loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4OwnTXnNCUu",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77a5a1ecd1574358970a2d3edf7aad59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aae031ee890141b59d080cf272942f96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc3071d8be6642fe8ab50684896eaa97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c22d72bfc9a64296933f85f5c376e308",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20251030_181859-n7iu1ygz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ronchaudhuri29-the-university-of-texas-at-dallas/huggingface/runs/n7iu1ygz' target=\"_blank\">partA_gemma_lora_bce_cosine</a></strong> to <a href='https://wandb.ai/ronchaudhuri29-the-university-of-texas-at-dallas/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ronchaudhuri29-the-university-of-texas-at-dallas/huggingface' target=\"_blank\">https://wandb.ai/ronchaudhuri29-the-university-of-texas-at-dallas/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ronchaudhuri29-the-university-of-texas-at-dallas/huggingface/runs/n7iu1ygz' target=\"_blank\">https://wandb.ai/ronchaudhuri29-the-university-of-texas-at-dallas/huggingface/runs/n7iu1ygz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='812' max='812' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [812/812 1:01:02, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.546825</td>\n",
       "      <td>0.711823</td>\n",
       "      <td>0.802721</td>\n",
       "      <td>0.572816</td>\n",
       "      <td>0.668555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.449340</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.752066</td>\n",
       "      <td>0.883495</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.149900</td>\n",
       "      <td>0.478972</td>\n",
       "      <td>0.822660</td>\n",
       "      <td>0.810185</td>\n",
       "      <td>0.849515</td>\n",
       "      <td>0.829384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.149900</td>\n",
       "      <td>0.571958</td>\n",
       "      <td>0.817734</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.844660</td>\n",
       "      <td>0.824645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 01:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.47897249460220337,\n",
       " 'eval_accuracy': 0.8226600985221675,\n",
       " 'eval_precision': 0.8101851851851852,\n",
       " 'eval_recall': 0.8495145631067961,\n",
       " 'eval_f1': 0.8293838862559242,\n",
       " 'eval_runtime': 63.2136,\n",
       " 'eval_samples_per_second': 6.423,\n",
       " 'eval_steps_per_second': 0.807,\n",
       " 'epoch': 4.0}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np, evaluate\n",
    "from transformers import TrainingArguments, Trainer, DataCollatorWithPadding\n",
    "from transformers.trainer_utils import IntervalStrategy\n",
    "\n",
    "\n",
    "# --- metrics (sigmoid -> 0/1) ---\n",
    "acc  = evaluate.load(\"accuracy\")\n",
    "prec = evaluate.load(\"precision\")\n",
    "rec  = evaluate.load(\"recall\")\n",
    "f1   = evaluate.load(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    probs = 1 / (1 + np.exp(-logits.reshape(-1)))\n",
    "    preds = (probs >= 0.5).astype(int)\n",
    "    labels = labels.astype(int)\n",
    "    return {\n",
    "        \"accuracy\":  acc.compute(predictions=preds, references=labels)[\"accuracy\"],\n",
    "        \"precision\": prec.compute(predictions=preds, references=labels, average=\"binary\")[\"precision\"],\n",
    "        \"recall\":    rec.compute(predictions=preds, references=labels, average=\"binary\")[\"recall\"],\n",
    "        \"f1\":        f1.compute(predictions=preds, references=labels, average=\"binary\")[\"f1\"],\n",
    "    }\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"gemma_lora_binary_out\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=8,\n",
    "    gradient_accumulation_steps=2,\n",
    "    num_train_epochs=4,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_ratio=0.05,\n",
    "    eval_strategy=IntervalStrategy.EPOCH,\n",
    "    save_strategy=IntervalStrategy.EPOCH,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    fp16=True,\n",
    "    gradient_checkpointing=True,\n",
    "    report_to=[\"wandb\"],\n",
    "    run_name=\"partA_gemma_lora_bce_cosine\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "trainer = BCETrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"valid\"],\n",
    "    processing_class=tokenizer,          # ‚Üê replaces tokenizer=tokenizer\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WiO2xgl8pnpH",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit\n",
    "\n",
    "def to_probs(pred_array):\n",
    "    \"\"\"\n",
    "    Convert logits to probabilities exactly once.\n",
    "    If inputs already look like probabilities [0,1], return them unchanged.\n",
    "    \"\"\"\n",
    "    x = np.asarray(pred_array).squeeze()\n",
    "    if x.ndim == 0:\n",
    "        x = np.array([x])\n",
    "    if np.all((0.0 <= x) & (x <= 1.0)):   # already probabilities\n",
    "        return x\n",
    "    return expit(x)                      # logits -> probs (single sigmoid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kDX_OpxKq-HK",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1 on validation = 0.834467 at threshold = 0.330\n",
      "\n",
      "================================================================================\n",
      "Classification report @ threshold=0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8368    0.7950    0.8154       200\n",
      "           1     0.8102    0.8495    0.8294       206\n",
      "\n",
      "    accuracy                         0.8227       406\n",
      "   macro avg     0.8235    0.8223    0.8224       406\n",
      "weighted avg     0.8233    0.8227    0.8225       406\n",
      "\n",
      "Confusion matrix:\n",
      "[[159  41]\n",
      " [ 31 175]]\n",
      "ROC-AUC (threshold-free): 0.890316\n",
      "\n",
      "================================================================================\n",
      "Classification report @ threshold=0.330\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8713    0.7450    0.8032       200\n",
      "           1     0.7830    0.8932    0.8345       206\n",
      "\n",
      "    accuracy                         0.8202       406\n",
      "   macro avg     0.8272    0.8191    0.8189       406\n",
      "weighted avg     0.8265    0.8202    0.8191       406\n",
      "\n",
      "Confusion matrix:\n",
      "[[149  51]\n",
      " [ 22 184]]\n",
      "ROC-AUC (threshold-free): 0.890316\n"
     ]
    }
   ],
   "source": [
    "# ---- VALIDATION EVAL (NO DOUBLE SIGMOID) ----\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, roc_auc_score\n",
    "\n",
    "# 1) Get logits & labels from the trained trainer\n",
    "pred_val = trainer.predict(tokenized_dataset[\"valid\"])\n",
    "logits   = pred_val.predictions                 # shape: (N, 1) or (N,)\n",
    "labels   = pred_val.label_ids.astype(int)\n",
    "\n",
    "# 2) Convert logits -> probabilities ONCE (safe helper you added)\n",
    "probs = to_probs(logits)                        # returns shape (N,)\n",
    "\n",
    "# 3) Quick scan to choose best threshold by F1 (optional: tighten/expand range)\n",
    "ts = np.linspace(0.20, 0.80, 61)\n",
    "best_t, best_f1 = 0.5, -1.0\n",
    "for t in ts:\n",
    "    preds_t = (probs >= t).astype(int)\n",
    "    f1_t = f1_score(labels, preds_t)\n",
    "    if f1_t > best_f1:\n",
    "        best_f1, best_t = f1_t, t\n",
    "\n",
    "print(f\"Best F1 on validation = {best_f1:.6f} at threshold = {best_t:.3f}\")\n",
    "\n",
    "# 4) Reports at default 0.5 and at best_t\n",
    "for name, t in [(\"0.5\", 0.5), (f\"{best_t:.3f}\", best_t)]:\n",
    "    preds_t = (probs >= t).astype(int)\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"Classification report @ threshold={name}\")\n",
    "    print(classification_report(labels, preds_t, digits=4))\n",
    "    print(\"Confusion matrix:\")\n",
    "    print(confusion_matrix(labels, preds_t))\n",
    "    print(f\"ROC-AUC (threshold-free): {roc_auc_score(labels, probs):.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "knIzOSMs9uqo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model + tokenizer + threshold ‚Üí partA_cls_artifacts\n"
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "ART_DIR = \"partA_cls_artifacts\"\n",
    "os.makedirs(ART_DIR, exist_ok=True)\n",
    "\n",
    "model.save_pretrained(os.path.join(ART_DIR, \"lora_adapter\"))\n",
    "tokenizer.save_pretrained(os.path.join(ART_DIR, \"tokenizer\"))\n",
    "\n",
    "with open(os.path.join(ART_DIR, \"inference_config.json\"), \"w\") as f:\n",
    "    json.dump({\"best_threshold\": float(0.33)}, f, indent=2)\n",
    "\n",
    "print(\"Saved model + tokenizer + threshold ‚Üí\", ART_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7QcMxqqLv7B7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved submission to: submission_partA_gemma2_lora.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "pred_test  = trainer.predict(tokenized_test)\n",
    "test_probs = to_probs(pred_test.predictions)\n",
    "test_preds = (test_probs >= best_t).astype(int)\n",
    "\n",
    "sub = sample_sub.copy()\n",
    "\n",
    "if \"rule_violation\" in sub.columns:\n",
    "    sub[\"rule_violation\"] = test_preds\n",
    "elif \"label\" in sub.columns:\n",
    "    sub[\"label\"] = test_preds\n",
    "else:\n",
    "\n",
    "    sub[\"label\"] = test_preds\n",
    "\n",
    "SUB_PATH = \"submission_partA_gemma2_lora.csv\"\n",
    "sub.to_csv(SUB_PATH, index=False)\n",
    "print(f\"Saved submission to: {SUB_PATH}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
