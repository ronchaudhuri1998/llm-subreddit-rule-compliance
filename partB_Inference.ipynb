{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b84121b7-f061-4e3b-8e4d-95e94859115b",
   "metadata": {
    "id": "b84121b7-f061-4e3b-8e4d-95e94859115b"
   },
   "source": [
    "# <font color = 'indianred'>**Decoder_Base_Language_Head_Inference_Binary** </font>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fj41POPjrtzA",
   "metadata": {
    "id": "fj41POPjrtzA"
   },
   "source": [
    "# <font color = 'indianred'> **Setting up the Environment** </font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d54de23-80e9-4e1b-816c-6f6916c92836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m126.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.4 which is incompatible.\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.4 which is incompatible.\n",
      "cupy-cuda12x 13.3.0 requires numpy<2.3,>=1.22, but you have numpy 2.3.4 which is incompatible.\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.4 which is incompatible.\n",
      "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.4 which is incompatible.\n",
      "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.3.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m88.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m506.8/506.8 kB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m423.1/423.1 kB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.2/438.2 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.0/180.0 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.0/111.0 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.4/45.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m135.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m83.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.2/117.2 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m118.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.2/96.2 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.0/15.0 MB\u001b[0m \u001b[31m114.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m121.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m120.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m124.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.4/71.4 MB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.2/102.2 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.0/388.0 kB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m285.7/285.7 kB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.6/213.6 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.7/180.7 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m456.8/456.8 kB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m331.1/331.1 kB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.7/517.7 kB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m110.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m98.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m959.8/959.8 kB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
      "pylibcudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\n",
      "cudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\n",
      "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.2.6 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mFound existing installation: tensorflow 2.19.0\n",
      "Uninstalling tensorflow-2.19.0:\n",
      "  Would remove:\n",
      "    /usr/local/bin/import_pb_to_tensorboard\n",
      "    /usr/local/bin/saved_model_cli\n",
      "    /usr/local/bin/tensorboard\n",
      "    /usr/local/bin/tf_upgrade_v2\n",
      "    /usr/local/bin/tflite_convert\n",
      "    /usr/local/bin/toco\n",
      "    /usr/local/lib/python3.12/dist-packages/tensorflow-2.19.0.dist-info/*\n",
      "    /usr/local/lib/python3.12/dist-packages/tensorflow/*\n",
      "Proceed (Y/n)? Y\n",
      "  Successfully uninstalled tensorflow-2.19.0\n"
     ]
    }
   ],
   "source": [
    "# If in Colab, then import the drive module from google.colab\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "  !pip install numpy -U -qq\n",
    "  !pip install transformers evaluate wandb datasets accelerate trl peft bitsandbytes vllm -U -qq\n",
    "  !pip uninstall tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cYPc8606XOHv",
   "metadata": {
    "id": "cYPc8606XOHv"
   },
   "source": [
    " <Font size = 5 color = 'indianred'>**Restart the session before moving onto next cell**\n",
    "> Runtime- Restart Session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1Kcz9H4QsW6_",
   "metadata": {
    "id": "1Kcz9H4QsW6_"
   },
   "source": [
    "<font color = 'indianred'> *Load Libraries* </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "RAVd4EzpauzE",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 11-03 02:02:29 [__init__.py:216] Automatically detected platform cuda.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['VLLM_USE_V1'] = '1' # this should be done befre any other import\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from vllm import LLM, SamplingParams\n",
    "from vllm.lora.request import LoRARequest\n",
    "from vllm.sampling_params import GuidedDecodingParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "yC6lJrxYvxeF",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard pythgion libraries\n",
    "from pathlib import Path\n",
    "\n",
    "from typing import Dict, List, Union, Optional, Tuple\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import re\n",
    "import gc\n",
    "import time\n",
    "\n",
    "# Data Science librraies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, precision_score, accuracy_score, recall_score, f1_score\n",
    "from pprint import pprint\n",
    "\n",
    "# Pytorch\n",
    "import torch\n",
    "\n",
    "# Huggingface Librraies\n",
    "import evaluate\n",
    "from datasets import load_dataset\n",
    "\n",
    "from huggingface_hub import login\n",
    "\n",
    "# Logging and secrets\n",
    "import wandb\n",
    "from google.colab import userdata\n",
    "from huggingface_hub import login, HfApi, create_repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "lkR7CvSxopiE",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# Determine the storage location based on the execution environment\n",
    "# If running on Google Colab, use Google Drive as storage\n",
    "# CHANGE FOLDERS TO WHERE YOU WANT TO SAVE DATA AND MODELS\n",
    "\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    from google.colab import drive  # Import Google Drive mounting utility\n",
    "    drive.mount('/content/drive')  # Mount Google Drive\n",
    "\n",
    "    # Set base folder path for storing data on Google Drive\n",
    "    base_folder= Path('/content/drive/MyDrive/data')\n",
    "\n",
    "# If running locally, specify a different path\n",
    "else:\n",
    "    # Set base folder path for storing data on local machine\n",
    "    base_folder= Path('/Users/ronchaudhuri/Documents/Models/Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "MMk63r7U_G8t",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_api_key = userdata.get('WANDB_API_KEY')\n",
    "hf_token = userdata.get('HF_Token')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "k4jv63G1X9Uz",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully logged in to Hugging Face!\n"
     ]
    }
   ],
   "source": [
    "if hf_token:\n",
    "    # Log in to Hugging Face\n",
    "    login(token=hf_token)\n",
    "    print(\"Successfully logged in to Hugging Face!\")\n",
    "else:\n",
    "    print(\"Hugging Face token not found in notebook secrets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6aGXWhk4bWTO",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
      "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mronchaudhuri29\u001b[0m (\u001b[33mronchaudhuri29-the-university-of-texas-at-dallas\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully logged in to WANDB!\n"
     ]
    }
   ],
   "source": [
    "if wandb_api_key:\n",
    "  wandb.login(key=wandb_api_key)\n",
    "  print(\"Successfully logged in to WANDB!\")\n",
    "else:\n",
    "    print(\"WANDB key not found in notebook secrets.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b906904c-8f24-4de0-8e07-720863e8cd99",
   "metadata": {
    "id": "b906904c-8f24-4de0-8e07-720863e8cd99"
   },
   "source": [
    "# <font color = 'indianred'> **Load Data set**\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "Kjh2YTgXbcDF",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "077a579d5a194f3ebf7e7e68d515e065",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/538 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb5899bf2679423ca8c3f3601483d3e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00000-of-00001.parquet:   0%|          | 0.00/245k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aab510e16c5941cc8f3e6c5f2770ba4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/valid-00000-of-00001.parquet:   0%|          | 0.00/32.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90bbd5641bd7409199d464bf4c7a10d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/test-00000-of-00001.parquet:   0%|          | 0.00/33.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "412588e7d694472f9b217c709005a910",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1623 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "640415b4a75c4b7490fa769c8572d54e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating valid split:   0%|          | 0/203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67d6b680020b4a1ebdc4f1c05f1af2d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'completion': ' violates',\n",
      " 'prompt': 'Does the following Reddit comment violate the subreddit rules? '\n",
      "           \"Answer 'complies' or 'violates'.\\n\"\n",
      "           '\\n'\n",
      "           'Comment: Comment: Hello \\n'\n",
      "           'my name is Ali Hadii am Yemeni but i am living in Saudi arabia '\n",
      "           'with student visa i have finished my education and required to go '\n",
      "           'back to yaman which i dont want to do fearing for my life due to '\n",
      "           'Yemeni Civil War i need help seeking asylum in Canada if you can '\n",
      "           'help in any way send me a message please i have no money and no '\n",
      "           'one .\\n'\n",
      "           ' | Rule: No legal advice: Do not offer or request legal advice. | '\n",
      "           'Subreddit: canada\\n'\n",
      "           'Answer:',\n",
      " 'tag': 1}\n"
     ]
    }
   ],
   "source": [
    "val_split = load_dataset('Ron00769/jigsaw_binary_base_language_head', split = 'valid')\n",
    "val_prompts = val_split['prompt']\n",
    "test_split = load_dataset('Ron00769/jigsaw_binary_base_language_head', split = 'test')\n",
    "test_prompts = test_split['prompt']\n",
    "print()\n",
    "pprint(val_split[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GUdVYJAecXs8",
   "metadata": {
    "id": "GUdVYJAecXs8"
   },
   "source": [
    "#  <font color = 'indianred'> **Download Model and setup vLLM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "CBvrKgAeLZJV",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "BASE_MODEL = \"google/gemma-2-2b\"\n",
    "LORA_ADAPTER = \"Ron00769/jigsaw_binary_base_language_head\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "US9XRF_NcR80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 11-03 02:04:16 [utils.py:233] non-default args: {'trust_remote_code': True, 'dtype': torch.bfloat16, 'gpu_memory_utilization': 0.6, 'disable_log_stats': True, 'enable_lora': True, 'max_lora_rank': 128, 'guided_decoding_backend': 'outlines', 'model': 'google/gemma-2-2b'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84294c5fe89b4149a2f296aaeb9d715a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/818 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 11-03 02:04:33 [model.py:547] Resolved architecture: Gemma2ForCausalLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 11-03 02:04:33 [model.py:1730] Downcasting torch.float32 to torch.bfloat16.\n",
      "INFO 11-03 02:04:33 [model.py:1510] Using max model len 8192\n",
      "INFO 11-03 02:04:33 [scheduler.py:205] Chunked prefill is enabled with max_num_batched_tokens=8192.\n",
      "WARNING 11-03 02:04:33 [lora.py:92] `lora_extra_vocab_size` is deprecated and will be removed in v0.12.0. Additional vocabulary support for LoRA adapters is being phased out.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad4644a517424822ad3f69546e489e5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/46.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0ae8d7291f34c22b72df0e41f539fe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9645724412ba480f85ca0bb0c063fd92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7c8e965986947f69532531ec6f8214a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/636 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc3fd8651f0b4224ac3190244773ce9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/168 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 11-03 02:04:38 [__init__.py:3036] We must use the `spawn` multiprocessing start method. Overriding VLLM_WORKER_MULTIPROC_METHOD to 'spawn'. See https://docs.vllm.ai/en/latest/usage/troubleshooting.html#python-multiprocessing for more information. Reasons: CUDA is initialized\n",
      "INFO 11-03 02:06:46 [llm.py:306] Supported_tasks: ['generate']\n"
     ]
    }
   ],
   "source": [
    "llm = LLM(\n",
    "    model=BASE_MODEL,\n",
    "    dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "    enable_lora=True,\n",
    "    max_lora_rank=128,\n",
    "    gpu_memory_utilization=0.6,\n",
    "    guided_decoding_backend=\"outlines\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "QFkX_LOScjYp",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-1960497631.py:11: DeprecationWarning: guided_decoding is deprecated. This will be removed in v0.12.0 or v1.0.0, which ever is soonest. Please use structured_outputs instead.\n",
      "  sampling_params = SamplingParams(\n"
     ]
    }
   ],
   "source": [
    "lora_request = LoRARequest(\n",
    "    lora_name=\"jigsaw_binary_lora\",\n",
    "    lora_int_id=1,\n",
    "    lora_path=LORA_ADAPTER\n",
    ")\n",
    "\n",
    "GUIDE_REGEX = \"(complies|violates)\"\n",
    "guided_decoding = GuidedDecodingParams(regex=GUIDE_REGEX)\n",
    "\n",
    "\n",
    "sampling_params = SamplingParams(\n",
    "    temperature=0,\n",
    "    max_tokens=2,\n",
    "    guided_decoding=guided_decoding,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PRgHfq_mc1IP",
   "metadata": {
    "id": "PRgHfq_mc1IP"
   },
   "source": [
    "# <font color = 'indianred'> **Setup WandB**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "VEVzO7Etc8ls",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_PROJECT=jigsaw_language_head_2025\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20251103_020705-gucl8k4n</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/ronchaudhuri29-the-university-of-texas-at-dallas/jigsaw_language_head_2025/runs/gucl8k4n' target=\"_blank\">jigsaw_exp_lmh_gemma_base</a></strong> to <a href='https://wandb.ai/ronchaudhuri29-the-university-of-texas-at-dallas/jigsaw_language_head_2025' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ronchaudhuri29-the-university-of-texas-at-dallas/jigsaw_language_head_2025' target=\"_blank\">https://wandb.ai/ronchaudhuri29-the-university-of-texas-at-dallas/jigsaw_language_head_2025</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ronchaudhuri29-the-university-of-texas-at-dallas/jigsaw_language_head_2025/runs/gucl8k4n' target=\"_blank\">https://wandb.ai/ronchaudhuri29-the-university-of-texas-at-dallas/jigsaw_language_head_2025/runs/gucl8k4n</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Detected [openai] in use.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: For more information, check out the docs at: https://weave-docs.wandb.ai/\n"
     ]
    }
   ],
   "source": [
    "%env WANDB_PROJECT=jigsaw_language_head_2025\n",
    "\n",
    "run = wandb.init(\n",
    "    project=\"jigsaw_language_head_2025\",\n",
    "    entity=\"ronchaudhuri29-the-university-of-texas-at-dallas\",\n",
    "    id=\"gucl8k4n\",\n",
    "    resume=\"must\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TZEGr1VKdq_G",
   "metadata": {
    "id": "TZEGr1VKdq_G"
   },
   "source": [
    "#<font color = 'indianred'> **Utility Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "esPnM3OTdlDj",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predictions_batch(prompts: List[str],\n",
    "                               llm: LLM,\n",
    "                               sampling_params: SamplingParams,\n",
    "                               lora_request: LoRARequest,\n",
    "                               batch_size: int = 64) -> List[int]:\n",
    "    \"\"\"\n",
    "    Generate predictions for a list of prompts using vLLM batch inference.\n",
    "\n",
    "    Args:\n",
    "        prompts: List of input prompts\n",
    "        llm: vLLM model instance\n",
    "        sampling_params: Sampling parameters for generation\n",
    "        lora_request: LoRA adapter request\n",
    "        batch_size: Batch size for inference\n",
    "\n",
    "    Returns:\n",
    "         List of predicted labels as strings (\"complies\" or \"violates\")\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "\n",
    "    for i in tqdm(range(0, len(prompts), batch_size), desc=\"Generating predictions\"):\n",
    "        batch = prompts[i:i+batch_size]\n",
    "\n",
    "        outputs = llm.generate(\n",
    "            batch,\n",
    "            sampling_params,\n",
    "            lora_request=lora_request\n",
    "        )\n",
    "\n",
    "        for o in outputs:\n",
    "            text = (o.outputs[0].text or \"\").strip().lower()\n",
    "            if \"violates\" in text:\n",
    "                predictions.append(\"violates\")\n",
    "            elif \"complies\" in text:\n",
    "                predictions.append(\"complies\")\n",
    "            else:\n",
    "                predictions.append(\"unknown\")\n",
    "\n",
    "    print(f\"Processed {len(predictions)}/{len(prompts)} prompts\")\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eFAMfppkdwJz",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15c9162239a84f59aa3b12422a1faa75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f1 = evaluate.load(\"f1\")\n",
    "def compute_metrics(labels, preds):\n",
    "    f1_macro = f1.compute(predictions=preds, references=labels, average=\"macro\")\n",
    "    return {\"f1_macro\": f1_macro[\"f1\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "xVYVKzjoK3H8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_binary_predictions(true_labels: List[str],\n",
    "                                predictions: List[str],\n",
    "                                class_names: List[str],\n",
    "                                split_name: str = \"valid\",\n",
    "                                log_to_wandb: bool = True,\n",
    "                                show_confusion_matrix: bool = True) -> Dict:\n",
    "    \"\"\"\n",
    "    Evaluate binary predictions ('complies' vs 'violates') and optionally log to wandb.\n",
    "\n",
    "    Args:\n",
    "        true_labels: List of true labels (\"complies\" or \"violates\")\n",
    "        predictions: List of predicted labels (\"complies\" or \"violates\")\n",
    "        class_names: List of all possible class names\n",
    "        split_name: Name of the split (for wandb logging)\n",
    "        log_to_wandb: Whether to log metrics to wandb\n",
    "        show_confusion_matrix: Whether to display confusion matrix\n",
    "\n",
    "    Returns:\n",
    "        Dictionary containing evaluation metrics\n",
    "    \"\"\"\n",
    "    # Convert labels to lowercase\n",
    "    true_labels = [str(l).strip().lower() for l in true_labels]\n",
    "    predictions = [str(p).strip().lower() for p in predictions]\n",
    "\n",
    "    # Print samples and shapes\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"{split_name.upper()} SET EVALUATION\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Sample true labels: {true_labels[:3]}\")\n",
    "    print(f\"Sample predictions: {predictions[:3]}\")\n",
    "\n",
    "    # Compute metrics\n",
    "    f1_macro = f1_score(true_labels, predictions, average=\"macro\")\n",
    "    acc = accuracy_score(true_labels, predictions)\n",
    "\n",
    "    print(f\"\\nMetrics:\")\n",
    "    print(f\"  Accuracy: {acc:.4f}\")\n",
    "    print(f\"  F1 Macro: {f1_macro:.4f}\")\n",
    "\n",
    "    # Log to wandb\n",
    "    if log_to_wandb:\n",
    "        wandb.log({\n",
    "            f\"{split_name}_accuracy\": acc,\n",
    "            f\"{split_name}_f1_macro\": f1_macro\n",
    "        })\n",
    "        print(f\"  ✓ Logged to wandb\")\n",
    "\n",
    "    # Display confusion matrix\n",
    "    if show_confusion_matrix:\n",
    "        print(f\"\\nConfusion Matrix:\")\n",
    "        cm = confusion_matrix(true_labels, predictions, labels=class_names)\n",
    "        print(cm)\n",
    "\n",
    "    return {\"accuracy\": acc, \"f1_macro\": f1_macro}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tGzsqvqRd5Bu",
   "metadata": {
    "id": "tGzsqvqRd5Bu"
   },
   "source": [
    "#<font color = 'indianred'> **Performance on Validation Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "Tfiz-b04g5SR",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define class names (used for both validation and test)\n",
    "class_names = [\"complies\", \"violates\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "wotpqN5feTeX",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating predictions:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "226c3fc748db4c5ea1d84c0da6d3d07e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 11-03 02:07:29 [processor.py:215] vLLM has deprecated support for supporting different tokenizers for different LoRAs. By default, vLLM uses base model's tokenizer. If you are using a LoRA with its own tokenizer, consider specifying `--tokenizer [lora_path]` to use the LoRA tokenizer.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96603c3e13024a00b90d221c9a91082b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/64 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating predictions:  25%|██▌       | 1/4 [00:32<01:36, 32.24s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54838d87e29b4ab3aadb729b6413bcb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29e5c00b6aa744c1a836d1c19047d122",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/64 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating predictions:  50%|█████     | 2/4 [00:32<00:26, 13.43s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc213b3cb24a4c2eb9b79d081afe2f62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f3ea40559ab49a7bab0339211485aff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/64 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating predictions:  75%|███████▌  | 3/4 [00:32<00:07,  7.41s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28cab9b8ba0b499ebb4b6ca46d7ee86d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "884251d58ad74354ae35bc1244838d8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/11 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating predictions: 100%|██████████| 4/4 [00:32<00:00,  8.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 203/203 prompts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "val_predictions = generate_predictions_batch(\n",
    "    prompts=val_prompts, # Extract the prompt string\n",
    "    llm=llm,\n",
    "    sampling_params=sampling_params,\n",
    "    lora_request=lora_request,\n",
    "    batch_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "A_7naoA8fTPe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['violates', 'complies', 'complies', 'violates', 'complies']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_predictions[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "qW3C0ABWfX7F",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "VALID SET EVALUATION\n",
      "============================================================\n",
      "Sample true labels: ['violates', 'violates', 'complies']\n",
      "Sample predictions: ['violates', 'complies', 'complies']\n",
      "\n",
      "Metrics:\n",
      "  Accuracy: 0.6453\n",
      "  F1 Macro: 0.4177\n",
      "  ✓ Logged to wandb\n",
      "\n",
      "Confusion Matrix:\n",
      "[[92 10]\n",
      " [57 39]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "valid_metrics = evaluate_binary_predictions(\n",
    "    true_labels=val_split['completion'],\n",
    "    predictions=val_predictions,\n",
    "    class_names=class_names,\n",
    "    split_name=\"valid\",\n",
    "    log_to_wandb=True,\n",
    "    show_confusion_matrix=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "C2D0yGsSf9_F",
   "metadata": {
    "id": "C2D0yGsSf9_F"
   },
   "source": [
    "#  <font color = 'indianred'> **Performance on Test Set** </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "qyAJCrw1gEfZ",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating predictions:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83deccbedfad4240a0ccbc37ba8700f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8759f6a5329b494e9be95826db6d1d60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/128 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating predictions:  50%|█████     | 1/2 [00:00<00:00,  2.06it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3c00cff7ccd408ea0019d5e6137abda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cebd9b2af15c49e286ad9f1d1d2c4faa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/75 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating predictions: 100%|██████████| 2/2 [00:00<00:00,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 203/203 prompts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions\n",
    "test_predictions = generate_predictions_batch(\n",
    "    prompts=test_prompts,\n",
    "    llm=llm,\n",
    "    sampling_params=sampling_params,\n",
    "    lora_request=lora_request,\n",
    "    batch_size=128  # Can use larger batch for test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "F5AiHvGXgJxo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TEST SET EVALUATION\n",
      "============================================================\n",
      "Sample true labels: ['complies', 'violates', 'complies']\n",
      "Sample predictions: ['complies', 'complies', 'complies']\n",
      "\n",
      "Metrics:\n",
      "  Accuracy: 0.5961\n",
      "  F1 Macro: 0.3879\n",
      "  ✓ Logged to wandb\n",
      "\n",
      "Confusion Matrix:\n",
      "[[81 15]\n",
      " [65 40]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "test_metrics = evaluate_binary_predictions(\n",
    "    true_labels=test_split['completion'],\n",
    "    predictions=test_predictions,\n",
    "    class_names=class_names,\n",
    "    split_name=\"test\",\n",
    "    log_to_wandb=True,\n",
    "    show_confusion_matrix=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b-yRA-4lgWri",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_f1_macro</td><td>▁</td></tr><tr><td>valid_accuracy</td><td>▁</td></tr><tr><td>valid_f1_macro</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/entropy</td><td>2.49263</td></tr><tr><td>eval/loss</td><td>0.3018</td></tr><tr><td>eval/mean_token_accuracy</td><td>0.85294</td></tr><tr><td>eval/num_tokens</td><td>327473</td></tr><tr><td>eval/runtime</td><td>20.3923</td></tr><tr><td>eval/samples_per_second</td><td>9.955</td></tr><tr><td>eval/steps_per_second</td><td>5.002</td></tr><tr><td>test_accuracy</td><td>0.59606</td></tr><tr><td>test_f1_macro</td><td>0.38785</td></tr><tr><td>total_flos</td><td>4774549580646912</td></tr><tr><td>+14</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">jigsaw_exp_lmh_gemma_base</strong> at: <a href='https://wandb.ai/ronchaudhuri29-the-university-of-texas-at-dallas/jigsaw_language_head_2025/runs/gucl8k4n' target=\"_blank\">https://wandb.ai/ronchaudhuri29-the-university-of-texas-at-dallas/jigsaw_language_head_2025/runs/gucl8k4n</a><br> View project at: <a href='https://wandb.ai/ronchaudhuri29-the-university-of-texas-at-dallas/jigsaw_language_head_2025' target=\"_blank\">https://wandb.ai/ronchaudhuri29-the-university-of-texas-at-dallas/jigsaw_language_head_2025</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251103_020705-gucl8k4n/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Finish wandb run\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4sCd7m44gglN",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"Does the following Reddit comment violate the subreddit rules? Answer 'complies' or 'violates'.\\n\\nComment: Comment: Hello \\nmy name is Ali Hadii am Yemeni but i am living in Saudi arabia with student visa i have finished my education and required to go back to yaman which i dont want to do fearing for my life due to Yemeni Civil War i need help seeking asylum in Canada if you can help in any way send me a message please i have no money and no one .\\n | Rule: No legal advice: Do not offer or request legal advice. | Subreddit: canada\\nAnswer:\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = val_split['prompt'][0]\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6hN0OLecglWY",
   "metadata": {
    "id": "6hN0OLecglWY"
   },
   "source": [
    "# <font color = 'indianred'> **Inference** </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kqh7uIcOgv_M",
   "metadata": {
    "id": "kqh7uIcOgv_M"
   },
   "source": [
    "# <font color = 'indianred'> **Load Data set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "GSXnLpusDOGT",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df_inference\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"row_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 2029,\n        \"max\": 2038,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          2037,\n          2030,\n          2034\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"body\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"must be watch movie https://sites.google.com/site/greatescape1963xx/-the-avengers-2012-hd-movie\",\n          \"Make your life comfortable. Get up to 15% Discount. Pain killers Like Roxycodone, Hydrocodone, Codeine, Percocet, Hydrocodone, Oxycodone and Lortab. Also get full treatment of Depression, Insomnia and other such problems with Adderall, Ativan, **[Xanax](http://onestoppharma.org)**, Mogadon, Modafinil and Many Others Treatments Online **Without Prescription at [onestoppharma.org](http://onestoppharma.org)**\",\n          \"Top 10 Pentakills in August https://youtu.be/ZYOnLkrSHBw Please subscribe. Every day new Pentakill replays.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rule\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"No legal advice: Do not offer or request legal advice.\",\n          \"No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"subreddit\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"movies\",\n          \"AskReddit\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"positive_example_1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \" see  there  hooters  sweet  http://url.t.aylor.de/2176b\",\n          \"Get a lawyer and get the security camera footage of the entire store for that day. Maybe someone put the ingredient in her salad on purpose because they knew she was allergic. They could be charged with manslaughter. However, this is very unlikely.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"positive_example_2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Sign up with my link and get $1,000 of free processing! Thanks!\\n\\nhttps://squareup.com/i/DAE7E171\",\n          \"That isn't drastic. You tried reaching out to her directly. She avoided your calls/texts, and HUNG UP ON YOU as soon as she realized it was your voice on her work line.  \\n\\nBitch stole your puppy - a puppy that you are raising to be sold for profit. Effectively, she stole your property.  \\n\\nCall the police. ASAP.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"negative_example_1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"The fact that there are pro and cons to everything...thats why i created this website http://www.proandkon.com/\",\n          \"So what are you going to do with the insurance money when the house \\\"accidentally\\\" burns down?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"negative_example_2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Oh that's interesting. You should check out my instagram page \\\"dailyetymology\\\" for more cool etymology!\",\n          \"It's just for Austria & Germany. If you still need it, drop me a PM. I'm not sure if I'm allowed to name it here.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "df_inference"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-b8c7f7ed-3c85-409e-ad07-bb2fdd5e84ac\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>body</th>\n",
       "      <th>rule</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>positive_example_1</th>\n",
       "      <th>positive_example_2</th>\n",
       "      <th>negative_example_1</th>\n",
       "      <th>negative_example_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2029</td>\n",
       "      <td>NEW RAP GROUP 17. CHECK US OUT https://soundcl...</td>\n",
       "      <td>No Advertising: Spam, referral links, unsolici...</td>\n",
       "      <td>hiphopheads</td>\n",
       "      <td>Hey, guys, just wanted to drop in and invite y...</td>\n",
       "      <td>Cum Swallowing Hottie Katrina Kaif Cartoon Xvi...</td>\n",
       "      <td>SD Stream Eng - [Chelsea TV USA](http://soccer...</td>\n",
       "      <td>HD Streams: |[ENG HD Stoke vs Manchester Unite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2030</td>\n",
       "      <td>Make your life comfortable. Get up to 15% Disc...</td>\n",
       "      <td>No legal advice: Do not offer or request legal...</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>Get a lawyer and get the security camera foota...</td>\n",
       "      <td>That isn't drastic. You tried reaching out to ...</td>\n",
       "      <td>So what are you going to do with the insurance...</td>\n",
       "      <td>It's just for Austria &amp; Germany. If you still ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2031</td>\n",
       "      <td>Kickin' ass and selling underwear!\\nJust made ...</td>\n",
       "      <td>No Advertising: Spam, referral links, unsolici...</td>\n",
       "      <td>gonewild</td>\n",
       "      <td>Good story my friend. Check out my blog at  ht...</td>\n",
       "      <td>If you know what exactly you need then you don...</td>\n",
       "      <td>CENTIPEDES\\n\\nSOME BASED PATRIOTS HAVE CREATED...</td>\n",
       "      <td>[So great! Thanks for sharing.](http://www.che...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2032</td>\n",
       "      <td>watch  hooters  best  therein  http://clickan...</td>\n",
       "      <td>No Advertising: Spam, referral links, unsolici...</td>\n",
       "      <td>personalfinance</td>\n",
       "      <td>Earn 50,000 bonus points with Chase Sapphire P...</td>\n",
       "      <td>Cool, front page! I made this print along with...</td>\n",
       "      <td>[Full HD Movie Online Free](http://www.flickma...</td>\n",
       "      <td>* Karambit Black Pearl\\n* 0.02137822 Float (un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2033</td>\n",
       "      <td>bitches  for free  at this point  show all  h...</td>\n",
       "      <td>No Advertising: Spam, referral links, unsolici...</td>\n",
       "      <td>Showerthoughts</td>\n",
       "      <td>code free tyrande ---&gt;&gt;&gt; [Imgur](http://i.imgu...</td>\n",
       "      <td>My trade link\\nhttps://steamcommunity.com/trad...</td>\n",
       "      <td>**HD** [ mio Stadium 102 HD](http://www.genti....</td>\n",
       "      <td>Infographics is an incredible method for showi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2034</td>\n",
       "      <td>Top 10 Pentakills in August https://youtu.be/Z...</td>\n",
       "      <td>No Advertising: Spam, referral links, unsolici...</td>\n",
       "      <td>leagueoflegends</td>\n",
       "      <td>code free tyrande ---&gt;&gt;&gt; [Imgur](http://i.imgu...</td>\n",
       "      <td>see  tits  sweet  at this point  http://sh.or...</td>\n",
       "      <td>its my asreddit https://www.youtube.com/watch?...</td>\n",
       "      <td>click here for more videos[Russian mafia messe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2035</td>\n",
       "      <td>WIN A SAMSUNG SMARTWATCH!\\n\\nhttp://www.innomd...</td>\n",
       "      <td>No Advertising: Spam, referral links, unsolici...</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>[ENJOY 50,000 BONUS POINTS after $4,000 spent ...</td>\n",
       "      <td>We have high quality Canadian Polymer banknote...</td>\n",
       "      <td>i was on the same ios and try this jailbreak m...</td>\n",
       "      <td>We're streaming Pokemon Veitnamese Crystal RIG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2036</td>\n",
       "      <td>[This mixtape is lit FAM!](https://beholdthear...</td>\n",
       "      <td>No Advertising: Spam, referral links, unsolici...</td>\n",
       "      <td>BlackPeopleTwitter</td>\n",
       "      <td>watch good one hooters there http://https://x5...</td>\n",
       "      <td>bad pussies waiting for you herein http://gour...</td>\n",
       "      <td>[Full HD Movie Online Free](http://www.flickma...</td>\n",
       "      <td>* Computers :http://livematchstreamz.blogspot....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2037</td>\n",
       "      <td>must be watch movie https://sites.google.com/s...</td>\n",
       "      <td>No Advertising: Spam, referral links, unsolici...</td>\n",
       "      <td>movies</td>\n",
       "      <td>see  there  hooters  sweet  http://url.t.aylo...</td>\n",
       "      <td>Sign up with my link and get $1,000 of free pr...</td>\n",
       "      <td>The fact that there are pro and cons to everyt...</td>\n",
       "      <td>Oh that's interesting. You should check out my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2038</td>\n",
       "      <td>Free paypal cards here!! https://www.pointspri...</td>\n",
       "      <td>No Advertising: Spam, referral links, unsolici...</td>\n",
       "      <td>pics</td>\n",
       "      <td>she will come your home open her legs with  an...</td>\n",
       "      <td>Old and young  your girl-next-door make sex wi...</td>\n",
       "      <td>i think  the conjuring 2 is not bad movie ,The...</td>\n",
       "      <td>wow, she's so beautyful\\n&gt;[Sakura Vietnam](htt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b8c7f7ed-3c85-409e-ad07-bb2fdd5e84ac')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-b8c7f7ed-3c85-409e-ad07-bb2fdd5e84ac button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-b8c7f7ed-3c85-409e-ad07-bb2fdd5e84ac');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-ac3ffb2a-b5d5-4a47-a830-723424e08855\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ac3ffb2a-b5d5-4a47-a830-723424e08855')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-ac3ffb2a-b5d5-4a47-a830-723424e08855 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "  <div id=\"id_52b58044-bcee-4b4c-904a-1398f4f741ee\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_inference')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_52b58044-bcee-4b4c-904a-1398f4f741ee button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('df_inference');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   row_id                                               body  \\\n",
       "0    2029  NEW RAP GROUP 17. CHECK US OUT https://soundcl...   \n",
       "1    2030  Make your life comfortable. Get up to 15% Disc...   \n",
       "2    2031  Kickin' ass and selling underwear!\\nJust made ...   \n",
       "3    2032   watch  hooters  best  therein  http://clickan...   \n",
       "4    2033   bitches  for free  at this point  show all  h...   \n",
       "5    2034  Top 10 Pentakills in August https://youtu.be/Z...   \n",
       "6    2035  WIN A SAMSUNG SMARTWATCH!\\n\\nhttp://www.innomd...   \n",
       "7    2036  [This mixtape is lit FAM!](https://beholdthear...   \n",
       "8    2037  must be watch movie https://sites.google.com/s...   \n",
       "9    2038  Free paypal cards here!! https://www.pointspri...   \n",
       "\n",
       "                                                rule           subreddit  \\\n",
       "0  No Advertising: Spam, referral links, unsolici...         hiphopheads   \n",
       "1  No legal advice: Do not offer or request legal...           AskReddit   \n",
       "2  No Advertising: Spam, referral links, unsolici...            gonewild   \n",
       "3  No Advertising: Spam, referral links, unsolici...     personalfinance   \n",
       "4  No Advertising: Spam, referral links, unsolici...      Showerthoughts   \n",
       "5  No Advertising: Spam, referral links, unsolici...     leagueoflegends   \n",
       "6  No Advertising: Spam, referral links, unsolici...           AskReddit   \n",
       "7  No Advertising: Spam, referral links, unsolici...  BlackPeopleTwitter   \n",
       "8  No Advertising: Spam, referral links, unsolici...              movies   \n",
       "9  No Advertising: Spam, referral links, unsolici...                pics   \n",
       "\n",
       "                                  positive_example_1  \\\n",
       "0  Hey, guys, just wanted to drop in and invite y...   \n",
       "1  Get a lawyer and get the security camera foota...   \n",
       "2  Good story my friend. Check out my blog at  ht...   \n",
       "3  Earn 50,000 bonus points with Chase Sapphire P...   \n",
       "4  code free tyrande --->>> [Imgur](http://i.imgu...   \n",
       "5  code free tyrande --->>> [Imgur](http://i.imgu...   \n",
       "6  [ENJOY 50,000 BONUS POINTS after $4,000 spent ...   \n",
       "7  watch good one hooters there http://https://x5...   \n",
       "8   see  there  hooters  sweet  http://url.t.aylo...   \n",
       "9  she will come your home open her legs with  an...   \n",
       "\n",
       "                                  positive_example_2  \\\n",
       "0  Cum Swallowing Hottie Katrina Kaif Cartoon Xvi...   \n",
       "1  That isn't drastic. You tried reaching out to ...   \n",
       "2  If you know what exactly you need then you don...   \n",
       "3  Cool, front page! I made this print along with...   \n",
       "4  My trade link\\nhttps://steamcommunity.com/trad...   \n",
       "5   see  tits  sweet  at this point  http://sh.or...   \n",
       "6  We have high quality Canadian Polymer banknote...   \n",
       "7  bad pussies waiting for you herein http://gour...   \n",
       "8  Sign up with my link and get $1,000 of free pr...   \n",
       "9  Old and young  your girl-next-door make sex wi...   \n",
       "\n",
       "                                  negative_example_1  \\\n",
       "0  SD Stream Eng - [Chelsea TV USA](http://soccer...   \n",
       "1  So what are you going to do with the insurance...   \n",
       "2  CENTIPEDES\\n\\nSOME BASED PATRIOTS HAVE CREATED...   \n",
       "3  [Full HD Movie Online Free](http://www.flickma...   \n",
       "4  **HD** [ mio Stadium 102 HD](http://www.genti....   \n",
       "5  its my asreddit https://www.youtube.com/watch?...   \n",
       "6  i was on the same ios and try this jailbreak m...   \n",
       "7  [Full HD Movie Online Free](http://www.flickma...   \n",
       "8  The fact that there are pro and cons to everyt...   \n",
       "9  i think  the conjuring 2 is not bad movie ,The...   \n",
       "\n",
       "                                  negative_example_2  \n",
       "0  HD Streams: |[ENG HD Stoke vs Manchester Unite...  \n",
       "1  It's just for Austria & Germany. If you still ...  \n",
       "2  [So great! Thanks for sharing.](http://www.che...  \n",
       "3  * Karambit Black Pearl\\n* 0.02137822 Float (un...  \n",
       "4  Infographics is an incredible method for showi...  \n",
       "5  click here for more videos[Russian mafia messe...  \n",
       "6  We're streaming Pokemon Veitnamese Crystal RIG...  \n",
       "7  * Computers :http://livematchstreamz.blogspot....  \n",
       "8  Oh that's interesting. You should check out my...  \n",
       "9  wow, she's so beautyful\\n>[Sakura Vietnam](htt...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_folder = base_folder/'datasets'\n",
    "df_inference = pd.read_csv(data_folder/'test.csv')\n",
    "df_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aeTb8QtXHbkA",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify columns\n",
    "ID_COL = 'row_id'\n",
    "TEXT_COL = 'body'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "UvQ_R2nkI173",
   "metadata": {
    "id": "UvQ_R2nkI173"
   },
   "source": [
    "#  <font color = 'indianred'> **Build Prompt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "DYQH-MtsIzcz",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(text):\n",
    "    return (\n",
    "        \"Does the following Reddit comment violate the subreddit rules? \"\n",
    "        \"Answer 'complies' or 'violates'.\\n\\n\"\n",
    "        f\"Comment: {str(text).strip()}\\n\"\n",
    "        \"Answer:\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "pJCy6V7iigym",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [build_prompt(t) for t in df_inference[TEXT_COL]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8xsd5Yl9opay",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating predictions:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "152324eae59448a3a6313e6a7a5283f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69c7e4b7269c43bc929426adcd1fc607",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/10 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Generating predictions: 100%|██████████| 1/1 [00:00<00:00, 12.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10/10 prompts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "preds = generate_predictions_batch(\n",
    "    prompts=prompts,                #full list built from df_inference['body']\n",
    "    llm=llm,\n",
    "    sampling_params=sampling_params,\n",
    "    lora_request=lora_request,\n",
    "    batch_size=128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cLDplwlAo0Yk",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['complies', 'complies', 'violates', 'complies', 'complies', 'complies', 'complies', 'complies', 'complies', 'complies']\n"
     ]
    }
   ],
   "source": [
    "print(preds[:10])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
