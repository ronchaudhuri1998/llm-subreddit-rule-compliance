{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b84121b7-f061-4e3b-8e4d-95e94859115b",
   "metadata": {
    "id": "b84121b7-f061-4e3b-8e4d-95e94859115b"
   },
   "source": [
    "# <font color = 'indianred'>**Decoder_Instruction_LMHead_Binary** </font>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fj41POPjrtzA",
   "metadata": {
    "id": "fj41POPjrtzA"
   },
   "source": [
    "# <font color = 'indianred'> **Setting up the Environment** </font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5OFzqN90y5lZ",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Nov  3 02:22:23 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA A100-SXM4-80GB          Off |   00000000:00:05.0 Off |                    0 |\n",
      "| N/A   32C    P0             55W /  400W |       5MiB /  81920MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d54de23-80e9-4e1b-816c-6f6916c92836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping tensorflow as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# If in Colab, then import the drive module from google.colab\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "  !pip install numpy -U -qq\n",
    "  !pip install transformers evaluate wandb datasets accelerate trl peft bitsandbytes -U -qq\n",
    "  !pip uninstall tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PnUKYf-fuq1Y",
   "metadata": {
    "id": "PnUKYf-fuq1Y"
   },
   "source": [
    " <Font size = 5 color = 'indianred'>**Restart the session before moving onto next cell**\n",
    "> Runtime- Restart Session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1Kcz9H4QsW6_",
   "metadata": {
    "id": "1Kcz9H4QsW6_"
   },
   "source": [
    "<font color = 'indianred'> *Load Libraries* </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yC6lJrxYvxeF",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard python libraries\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Union, Optional, Tuple\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import joblib\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import re\n",
    "import gc\n",
    "import time\n",
    "\n",
    "# Data Science librraies\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "# Pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Huggingface Librraies\n",
    "import evaluate\n",
    "from datasets import load_dataset, DatasetDict, Dataset, ClassLabel\n",
    "from trl import SFTConfig, SFTTrainer\n",
    "from transformers import (\n",
    "    set_seed,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    AutoConfig,\n",
    "    BitsAndBytesConfig,\n",
    ")\n",
    "from peft import (\n",
    "    TaskType,\n",
    "    LoraConfig,\n",
    "    prepare_model_for_kbit_training,\n",
    "    get_peft_model,\n",
    "    AutoPeftModelForCausalLM,\n",
    "    PeftConfig\n",
    ")\n",
    "# Logging and secrets\n",
    "from huggingface_hub import login, HfApi, create_repo\n",
    "from google.colab import userdata\n",
    "import wandb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lkR7CvSxopiE",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# Determine the storage location based on the execution environment\n",
    "# If running on Google Colab, use Google Drive as storage\n",
    "# CHANGE FOLDERS TO WHERE YOU WANT TO SAVE DATA AND MODELS\n",
    "\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    from google.colab import drive  # Import Google Drive mounting utility\n",
    "    drive.mount('/content/drive')  # Mount Google Drive\n",
    "\n",
    "    # Set base folder path for storing data on Google Drive\n",
    "    base_folder= Path('/content/drive/MyDrive/data')\n",
    "\n",
    "# If running locally, specify a different path\n",
    "else:\n",
    "    # Set base folder path for storing data on local machine\n",
    "    base_folder= Path('/Users/ronchaudhuri/Documents/Models/Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f6686c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_api_key = userdata.get('WANDB_API_KEY')\n",
    "hf_token = userdata.get('HF_Token')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sKunx5nWvYbQ",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully logged in to Hugging Face!\n"
     ]
    }
   ],
   "source": [
    "if hf_token:\n",
    "    # Log in to Hugging Face\n",
    "    login(token=hf_token)\n",
    "    print(\"Successfully logged in to Hugging Face!\")\n",
    "else:\n",
    "    print(\"Hugging Face token not found in notebook secrets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "y7WznMn5vajX",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
      "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mronchaudhuri29\u001b[0m (\u001b[33mronchaudhuri29-the-university-of-texas-at-dallas\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully logged in to WANDB!\n"
     ]
    }
   ],
   "source": [
    "if wandb_api_key:\n",
    "  wandb.login(key=wandb_api_key)\n",
    "  print(\"Successfully logged in to WANDB!\")\n",
    "else:\n",
    "    print(\"WANDB key not found in notebook secrets.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b906904c-8f24-4de0-8e07-720863e8cd99",
   "metadata": {
    "id": "b906904c-8f24-4de0-8e07-720863e8cd99"
   },
   "source": [
    "# <font color = 'indianred'> **Load Data set**\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1JpTLLoCvuAY",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-c7392679-f2ea-4a32-85a7-2023a88fd2fd\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>body</th>\n",
       "      <th>rule</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>positive_example_1</th>\n",
       "      <th>positive_example_2</th>\n",
       "      <th>negative_example_1</th>\n",
       "      <th>negative_example_2</th>\n",
       "      <th>rule_violation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Banks don't want you to know this! Click here ...</td>\n",
       "      <td>No Advertising: Spam, referral links, unsolici...</td>\n",
       "      <td>Futurology</td>\n",
       "      <td>If you could tell your younger self something ...</td>\n",
       "      <td>hunt for lady for jack off in neighbourhood ht...</td>\n",
       "      <td>Watch Golden Globe Awards 2017 Live Online in ...</td>\n",
       "      <td>DOUBLE CEE x BANDS EPPS - \"BIRDS\"\\n\\nDOWNLOAD/...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>SD Stream [ ENG Link 1] (http://www.sportsstre...</td>\n",
       "      <td>No Advertising: Spam, referral links, unsolici...</td>\n",
       "      <td>soccerstreams</td>\n",
       "      <td>[I wanna kiss you all over! Stunning!](http://...</td>\n",
       "      <td>LOLGA.COM is One of the First Professional Onl...</td>\n",
       "      <td>#Rapper \\nðŸš¨Straight Outta Cross Keys SC ðŸš¨YouTu...</td>\n",
       "      <td>[15 Amazing Hidden Features Of Google Search Y...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Lol. Try appealing the ban and say you won't d...</td>\n",
       "      <td>No legal advice: Do not offer or request legal...</td>\n",
       "      <td>pcmasterrace</td>\n",
       "      <td>Don't break up with him or call the cops.  If ...</td>\n",
       "      <td>It'll be dismissed: https://en.wikipedia.org/w...</td>\n",
       "      <td>Where is there a site that still works where y...</td>\n",
       "      <td>Because this statement of his is true. It isn'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>she will come your home open her legs with  an...</td>\n",
       "      <td>No Advertising: Spam, referral links, unsolici...</td>\n",
       "      <td>sex</td>\n",
       "      <td>Selling Tyrande codes for 3â‚¬ to paypal. PM. \\n...</td>\n",
       "      <td>tight pussy watch for your cock get her at thi...</td>\n",
       "      <td>NSFW(obviously) http://spankbang.com/iy3u/vide...</td>\n",
       "      <td>Good News ::Download WhatsApp 2.16.230 APK for...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>code free tyrande ---&gt;&gt;&gt; [Imgur](http://i.imgu...</td>\n",
       "      <td>No Advertising: Spam, referral links, unsolici...</td>\n",
       "      <td>hearthstone</td>\n",
       "      <td>wow!! amazing reminds me of the old days.Well...</td>\n",
       "      <td>seek for lady for sex in around http://p77.pl/...</td>\n",
       "      <td>must be watch movie https://sites.google.com/s...</td>\n",
       "      <td>We're streaming Pokemon Veitnamese Crystal RIG...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024</th>\n",
       "      <td>2024</td>\n",
       "      <td>Please edit your post so it is readable. These...</td>\n",
       "      <td>No legal advice: Do not offer or request legal...</td>\n",
       "      <td>relationships</td>\n",
       "      <td>I'm not ok with this in anyway, and think you ...</td>\n",
       "      <td>See a lawyer under the guise that you want thi...</td>\n",
       "      <td>This is just untrue.  OP is 13, not an adult -...</td>\n",
       "      <td>Why should I care about all the bicyclists I i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025</th>\n",
       "      <td>2025</td>\n",
       "      <td>Yes, and in a right to work state they can eve...</td>\n",
       "      <td>No legal advice: Do not offer or request legal...</td>\n",
       "      <td>legaladvice</td>\n",
       "      <td>Move as much of your assets as you can offshor...</td>\n",
       "      <td>We have great consumer protection laws. There'...</td>\n",
       "      <td>LPT piratebay, transmission, vpn. Get the musi...</td>\n",
       "      <td>It's not so much that I killed them, it's that...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026</th>\n",
       "      <td>2026</td>\n",
       "      <td>**HD** Streams: |ENG **HD**[ Watch here..PC &amp; ...</td>\n",
       "      <td>No Advertising: Spam, referral links, unsolici...</td>\n",
       "      <td>soccerstreams</td>\n",
       "      <td>stitopdisca1987.tumblr.com - sex Take girl for...</td>\n",
       "      <td>this girl get sex going to  to old http://mrk....</td>\n",
       "      <td>NO ADS | NO ADS | NO ADS\\n\\nWe show all SOCCER...</td>\n",
       "      <td>[So great! Thanks for sharing.](http://www.che...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2027</th>\n",
       "      <td>2027</td>\n",
       "      <td>No. Not when doing so obviously presents a saf...</td>\n",
       "      <td>No legal advice: Do not offer or request legal...</td>\n",
       "      <td>politics</td>\n",
       "      <td>SHE ISNT A BIRTHING CHAMBER BUT EQUALLY THE BA...</td>\n",
       "      <td>Jail? What are you, ten years old? If they pro...</td>\n",
       "      <td>Who cares about that when I can keep raping in...</td>\n",
       "      <td>send me a private message; I may be able to he...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2028</th>\n",
       "      <td>2028</td>\n",
       "      <td>&gt; CA is an at fault state so they will not be ...</td>\n",
       "      <td>No legal advice: Do not offer or request legal...</td>\n",
       "      <td>legaladvice</td>\n",
       "      <td>[Yes, it is. In the USA, at least](https://www...</td>\n",
       "      <td>Never pay a civil demand. \\n\\nIt's a bluff and...</td>\n",
       "      <td>Where is there a site that still works where y...</td>\n",
       "      <td>Steal a car from an elderly person who won't n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2029 rows Ã— 9 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "      \n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c7392679-f2ea-4a32-85a7-2023a88fd2fd')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "      \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-c7392679-f2ea-4a32-85a7-2023a88fd2fd button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-c7392679-f2ea-4a32-85a7-2023a88fd2fd');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "  \n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "      row_id                                               body  \\\n",
       "0          0  Banks don't want you to know this! Click here ...   \n",
       "1          1  SD Stream [ ENG Link 1] (http://www.sportsstre...   \n",
       "2          2  Lol. Try appealing the ban and say you won't d...   \n",
       "3          3  she will come your home open her legs with  an...   \n",
       "4          4  code free tyrande --->>> [Imgur](http://i.imgu...   \n",
       "...      ...                                                ...   \n",
       "2024    2024  Please edit your post so it is readable. These...   \n",
       "2025    2025  Yes, and in a right to work state they can eve...   \n",
       "2026    2026  **HD** Streams: |ENG **HD**[ Watch here..PC & ...   \n",
       "2027    2027  No. Not when doing so obviously presents a saf...   \n",
       "2028    2028  > CA is an at fault state so they will not be ...   \n",
       "\n",
       "                                                   rule      subreddit  \\\n",
       "0     No Advertising: Spam, referral links, unsolici...     Futurology   \n",
       "1     No Advertising: Spam, referral links, unsolici...  soccerstreams   \n",
       "2     No legal advice: Do not offer or request legal...   pcmasterrace   \n",
       "3     No Advertising: Spam, referral links, unsolici...            sex   \n",
       "4     No Advertising: Spam, referral links, unsolici...    hearthstone   \n",
       "...                                                 ...            ...   \n",
       "2024  No legal advice: Do not offer or request legal...  relationships   \n",
       "2025  No legal advice: Do not offer or request legal...    legaladvice   \n",
       "2026  No Advertising: Spam, referral links, unsolici...  soccerstreams   \n",
       "2027  No legal advice: Do not offer or request legal...       politics   \n",
       "2028  No legal advice: Do not offer or request legal...    legaladvice   \n",
       "\n",
       "                                     positive_example_1  \\\n",
       "0     If you could tell your younger self something ...   \n",
       "1     [I wanna kiss you all over! Stunning!](http://...   \n",
       "2     Don't break up with him or call the cops.  If ...   \n",
       "3     Selling Tyrande codes for 3â‚¬ to paypal. PM. \\n...   \n",
       "4      wow!! amazing reminds me of the old days.Well...   \n",
       "...                                                 ...   \n",
       "2024  I'm not ok with this in anyway, and think you ...   \n",
       "2025  Move as much of your assets as you can offshor...   \n",
       "2026  stitopdisca1987.tumblr.com - sex Take girl for...   \n",
       "2027  SHE ISNT A BIRTHING CHAMBER BUT EQUALLY THE BA...   \n",
       "2028  [Yes, it is. In the USA, at least](https://www...   \n",
       "\n",
       "                                     positive_example_2  \\\n",
       "0     hunt for lady for jack off in neighbourhood ht...   \n",
       "1     LOLGA.COM is One of the First Professional Onl...   \n",
       "2     It'll be dismissed: https://en.wikipedia.org/w...   \n",
       "3     tight pussy watch for your cock get her at thi...   \n",
       "4     seek for lady for sex in around http://p77.pl/...   \n",
       "...                                                 ...   \n",
       "2024  See a lawyer under the guise that you want thi...   \n",
       "2025  We have great consumer protection laws. There'...   \n",
       "2026  this girl get sex going to  to old http://mrk....   \n",
       "2027  Jail? What are you, ten years old? If they pro...   \n",
       "2028  Never pay a civil demand. \\n\\nIt's a bluff and...   \n",
       "\n",
       "                                     negative_example_1  \\\n",
       "0     Watch Golden Globe Awards 2017 Live Online in ...   \n",
       "1     #Rapper \\nðŸš¨Straight Outta Cross Keys SC ðŸš¨YouTu...   \n",
       "2     Where is there a site that still works where y...   \n",
       "3     NSFW(obviously) http://spankbang.com/iy3u/vide...   \n",
       "4     must be watch movie https://sites.google.com/s...   \n",
       "...                                                 ...   \n",
       "2024  This is just untrue.  OP is 13, not an adult -...   \n",
       "2025  LPT piratebay, transmission, vpn. Get the musi...   \n",
       "2026  NO ADS | NO ADS | NO ADS\\n\\nWe show all SOCCER...   \n",
       "2027  Who cares about that when I can keep raping in...   \n",
       "2028  Where is there a site that still works where y...   \n",
       "\n",
       "                                     negative_example_2  rule_violation  \n",
       "0     DOUBLE CEE x BANDS EPPS - \"BIRDS\"\\n\\nDOWNLOAD/...               0  \n",
       "1     [15 Amazing Hidden Features Of Google Search Y...               0  \n",
       "2     Because this statement of his is true. It isn'...               1  \n",
       "3     Good News ::Download WhatsApp 2.16.230 APK for...               1  \n",
       "4     We're streaming Pokemon Veitnamese Crystal RIG...               1  \n",
       "...                                                 ...             ...  \n",
       "2024  Why should I care about all the bicyclists I i...               1  \n",
       "2025  It's not so much that I killed them, it's that...               0  \n",
       "2026  [So great! Thanks for sharing.](http://www.che...               1  \n",
       "2027  send me a private message; I may be able to he...               1  \n",
       "2028  Steal a car from an elderly person who won't n...               1  \n",
       "\n",
       "[2029 rows x 9 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_folder = base_folder/'datasets'\n",
    "df = pd.read_csv(data_folder/'train.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uvCUBOG-MDce",
   "metadata": {},
   "outputs": [],
   "source": [
    "jigsaw_dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quHN6VZYMRPp",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = {\n",
    "    \"text\": jigsaw_dataset[\"body\"],            # comment text\n",
    "    \"rule\": jigsaw_dataset[\"rule\"],            # subreddit rule\n",
    "    \"subreddit\": jigsaw_dataset[\"subreddit\"],  # subreddit name\n",
    "    \"tag\": jigsaw_dataset[\"rule_violation\"],   # label\n",
    "}\n",
    "jigsaw_selected_columns = Dataset.from_dict(selected_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ppklcWon_2Op",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the format to Pandas\n",
    "jigsaw_selected_columns.set_format(type='pandas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IUAryZtVMpT0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = jigsaw_selected_columns[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "h_xDJlY-dhUn",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df['tag'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "z8H8ykO42faN",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = (\n",
    "    \"COMMENT: \" + df[\"text\"].astype(str).str.strip() + \"\\n\"\n",
    "    + \"RULE: \" + df[\"rule\"].astype(str).str.strip() + \"\\n\"\n",
    "    + \"SUBREDDIT: \" + df[\"subreddit\"].astype(str).str.strip()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oopWWBvQNX7l",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label_text'] = df['label'].map({0: 'complies', 1: 'violates'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "R1072NtL2nV9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df[['text', 'label_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "R4c3ojVSNgLS",
   "metadata": {},
   "outputs": [],
   "source": [
    "jigsaw_selected_column_final = Dataset.from_pandas(df_final, preserve_index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bJnCcArQJ0Vd",
   "metadata": {
    "id": "bJnCcArQJ0Vd"
   },
   "source": [
    "# <font color = 'indianred'> **Accessing and Manuplating Splits**</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "F4Lpc6ItMyUi",
   "metadata": {
    "id": "F4Lpc6ItMyUi"
   },
   "source": [
    "<font color = 'indianred'>*Create futher subdivions of the splits*</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8YTYKAMhaV",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the test set into test and validation sets\n",
    "test_val_splits = jigsaw_selected_column_final.train_test_split(test_size=0.2, seed=42)\n",
    "train_split= test_val_splits['train']\n",
    "test_val_splits = test_val_splits['test'].train_test_split(test_size=0.5, seed=42,)\n",
    "val_split = test_val_splits['train']\n",
    "test_split = test_val_splits['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CY6NEjV6z7-i",
   "metadata": {
    "id": "CY6NEjV6z7-i"
   },
   "source": [
    "<font color = 'indianred'>*small subset for initial experimenttaion*</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IuEaHG3w150t",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_subset = DatasetDict({\"train\": train_split, \"valid\": val_split, \"test\": test_split})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wnB3lHD0kPW-",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label_text'],\n",
       "        num_rows: 1623\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['text', 'label_text'],\n",
       "        num_rows: 203\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label_text'],\n",
       "        num_rows: 203\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VgNj2At3kRSs",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"COMMENT: unethical but... make a SS# but state name and address and all perfectly.  If the IRS asks, just say that's the number you got, let the IRS sort if out for you.\\nRULE: No legal advice: Do not offer or request legal advice.\\nSUBREDDIT: personalfinance\",\n",
       " 'label_text': 'violates'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_subset['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7zR6_jfJvwNf",
   "metadata": {
    "id": "7zR6_jfJvwNf"
   },
   "source": [
    "# <font color = 'indianred'>**Load pre-trained Tokenizer**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pPGuUj3bZUDU",
   "metadata": {},
   "outputs": [],
   "source": [
    "def free_gpu_memory():\n",
    "    \"\"\"\n",
    "    Frees up GPU memory after CUDA out-of-memory error in Colab.\n",
    "\n",
    "    This function performs the following steps:\n",
    "    1. Deletes all PyTorch objects to clear references.\n",
    "    2. Calls garbage collection to remove unreferenced objects from memory.\n",
    "    3. Uses torch.cuda.empty_cache() to release cached GPU memory.\n",
    "    4. Waits for a moment to ensure memory is fully released.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Delete all torch tensors to free up memory\n",
    "        for obj in list(locals().values()):\n",
    "            if torch.is_tensor(obj):\n",
    "                del obj\n",
    "\n",
    "        # Collect garbage to release any remaining unused memory\n",
    "        gc.collect()\n",
    "\n",
    "        # Empty the CUDA cache to release GPU memory\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        # Adding a small delay to allow memory to be fully released\n",
    "        time.sleep(2)\n",
    "\n",
    "        print(\"GPU memory has been freed.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error while freeing GPU memory: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TKot11REvysI",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory has been freed.\n"
     ]
    }
   ],
   "source": [
    "free_gpu_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hzUiqZR6hI4o",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"google/gemma-2-2b-it\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4vsyN5kbyPQ",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'<eos>'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VlPaFtAQ-tnR",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'<pad>'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Tu9xXCUYgM26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'left'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.padding_side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dda69a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"{{ bos_token }}{% if messages[0]['role'] == 'system' %}{{ \"\n",
      " \"raise_exception('System role not supported') }}{% endif %}{% for message in \"\n",
      " \"messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ \"\n",
      " \"raise_exception('Conversation roles must alternate \"\n",
      " \"user/assistant/user/assistant/...') }}{% endif %}{% if (message['role'] == \"\n",
      " \"'assistant') %}{% set role = 'model' %}{% else %}{% set role = \"\n",
      " \"message['role'] %}{% endif %}{{ '<start_of_turn>' + role + '\\n\"\n",
      " \"' + message['content'] | trim + '<end_of_turn>\\n\"\n",
      " \"' }}{% endfor %}{% if add_generation_prompt %}{{'<start_of_turn>model\\n\"\n",
      " \"'}}{% endif %}\")\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(tokenizer.chat_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "K2UL0npttZvA",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing custom chat template...\n",
      "{'input_ids': [2, 106, 1645, 108, 2015, 107, 108, 106, 2516, 108, 3943, 107, 108], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'assistant_masks': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "Assistant tokens detected: 0\n"
     ]
    }
   ],
   "source": [
    "# 2. Test the template works\n",
    "print(\"Testing custom chat template...\")\n",
    "test_result = tokenizer.apply_chat_template(\n",
    "    [{\"role\": \"user\", \"content\": \"Test\"}, {\"role\": \"assistant\", \"content\": \"Response\"}],\n",
    "    return_dict=True,\n",
    "    return_assistant_tokens_mask=True,\n",
    "    add_generation_prompt=False\n",
    ")\n",
    "print(test_result)\n",
    "assistant_tokens = sum(test_result.get('assistant_masks', []))\n",
    "print(f\"Assistant tokens detected: {assistant_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MdznbVawpfkt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified template to only train on the actual content\n",
    "tokenizer.chat_template = \"\"\"\n",
    "{{ bos_token }}\n",
    "{% if messages[0]['role'] == 'system' %}\n",
    "  {{ raise_exception('System role not supported') }}\n",
    "{% endif %}\n",
    "{% for message in messages %}\n",
    "  {% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}\n",
    "    {{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}\n",
    "  {% endif %}\n",
    "  {% if message['role'] == 'assistant' %}\n",
    "<start_of_turn>model\n",
    "{% generation %}{{ message['content'] | trim }}{% endgeneration %}\n",
    "<end_of_turn>\n",
    "  {% else %}\n",
    "<start_of_turn>{{ message['role'] }}\n",
    "{{ message['content'] | trim }}\n",
    "<end_of_turn>\n",
    "  {% endif %}\n",
    "{% endfor %}\n",
    "{% if add_generation_prompt %}\n",
    "<start_of_turn>model\n",
    "{% endif %}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VBrN8fggtTMa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing custom chat template...\n",
      "{'input_ids': [108, 2, 108, 106, 1645, 108, 2015, 108, 107, 108, 106, 2516, 108, 3943, 107, 108], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'assistant_masks': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]}\n",
      "Assistant tokens detected: 1\n"
     ]
    }
   ],
   "source": [
    "# 2. Test the template works\n",
    "print(\"Testing custom chat template...\")\n",
    "test_result = tokenizer.apply_chat_template(\n",
    "    [{\"role\": \"user\", \"content\": \"Test\"}, {\"role\": \"assistant\", \"content\": \"Response\"}],\n",
    "    return_dict=True,\n",
    "    return_assistant_tokens_mask=True,\n",
    "    add_generation_prompt=False\n",
    ")\n",
    "print(test_result)\n",
    "assistant_tokens = sum(test_result.get('assistant_masks', []))\n",
    "print(f\"Assistant tokens detected: {assistant_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sND4V9jhuh78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Token-by-token breakdown:\n",
      "Index | Token ID | Token Text | Assistant?\n",
      "--------------------------------------------------\n",
      "    0 |      108 | '\\n'            | Other\n",
      "    1 |        2 | '<bos>'         | Other\n",
      "    2 |      108 | '\\n'            | Other\n",
      "    3 |      106 | '<start_of_turn>' | Other\n",
      "    4 |     1645 | 'user'          | Other\n",
      "    5 |      108 | '\\n'            | Other\n",
      "    6 |     2015 | 'Test'          | Other\n",
      "    7 |      108 | '\\n'            | Other\n",
      "    8 |      107 | '<end_of_turn>' | Other\n",
      "    9 |      108 | '\\n'            | Other\n",
      "   10 |      106 | '<start_of_turn>' | Other\n",
      "   11 |     2516 | 'model'         | Other\n",
      "   12 |      108 | '\\n'            | Other\n",
      "   13 |     3943 | 'Response'      | ASSISTANT\n",
      "   14 |      107 | '<end_of_turn>' | Other\n",
      "   15 |      108 | '\\n'            | Other\n",
      "\n",
      "Full text: '\\n<bos>\\n<start_of_turn>user\\nTest\\n<end_of_turn>\\n<start_of_turn>model\\nResponse<end_of_turn>\\n'\n",
      "Assistant-only text: 'Response'\n",
      "User/Other text: '\\n<bos>\\n<start_of_turn>user\\nTest\\n<end_of_turn>\\n<start_of_turn>model\\n<end_of_turn>\\n'\n"
     ]
    }
   ],
   "source": [
    "# Decode individual tokens to see what they are\n",
    "print(\"\\nToken-by-token breakdown:\")\n",
    "print(\"Index | Token ID | Token Text | Assistant?\")\n",
    "print(\"-\" * 50)\n",
    "input_ids = test_result['input_ids']\n",
    "assistant_masks = test_result['assistant_masks']\n",
    "\n",
    "for i, (token_id, is_assistant) in enumerate(zip(input_ids, assistant_masks)):\n",
    "    token_text = tokenizer.decode([token_id])\n",
    "    status = \"ASSISTANT\" if is_assistant else \"Other\"\n",
    "    print(f\"{i:5d} | {token_id:8d} | {repr(token_text):15s} | {status}\")\n",
    "\n",
    "print(f\"\\nFull text: {repr(tokenizer.decode(input_ids))}\")\n",
    "\n",
    "# Show only assistant tokens\n",
    "assistant_token_ids = [token_id for token_id, is_assistant in zip(input_ids, assistant_masks) if is_assistant]\n",
    "assistant_only_text = tokenizer.decode(assistant_token_ids)\n",
    "print(f\"Assistant-only text: {repr(assistant_only_text)}\")\n",
    "\n",
    "# Show the masked (non-assistant) tokens\n",
    "user_token_ids = [token_id for token_id, is_assistant in zip(input_ids, assistant_masks) if not is_assistant]\n",
    "user_only_text = tokenizer.decode(user_token_ids)\n",
    "print(f\"User/Other text: {repr(user_only_text)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4ce3b9-904f-42bd-9c3f-163328f47051",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T11:22:33.679936Z",
     "iopub.status.busy": "2022-12-20T11:22:33.679764Z",
     "iopub.status.idle": "2022-12-20T11:22:33.723366Z",
     "shell.execute_reply": "2022-12-20T11:22:33.722847Z",
     "shell.execute_reply.started": "2022-12-20T11:22:33.679918Z"
    },
    "id": "2b4ce3b9-904f-42bd-9c3f-163328f47051"
   },
   "source": [
    "#<font color = 'indianred'> **Create Chat Dataset**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PFRvJTd7MzwQ",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_chat(example):\n",
    "    instruction = (\n",
    "        \"You are a content policy checker. Analyze the given COMMENT, RULE, \"\n",
    "        \"and SUBREDDIT context below. Output exactly one word:\\n\"\n",
    "        \"- 'complies' if the comment follows the subreddit rules, or\\n\"\n",
    "        \"- 'violates' if it breaks them.\\n\\n\"\n",
    "        f\"{example['text']}\"\n",
    "    )\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": instruction},\n",
    "        {\"role\": \"assistant\", \"content\": example[\"label_text\"]}\n",
    "    ]\n",
    "\n",
    "    return {\"messages\": messages}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NXw2qlGKJvuA",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c615bf58fd045929d73885d2cf7db46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1623 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62738aeb5a674c3f9595805c463a57a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e04c38217b664b008225dd00e34e1738",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_subset_chat = data_subset.map(format_chat, remove_columns=[\"text\",\"label_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26MsfYeILJpO",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['messages'],\n",
       "        num_rows: 1623\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['messages'],\n",
       "        num_rows: 203\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['messages'],\n",
       "        num_rows: 203\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_subset_chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52VW86pfJ3Pr",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'content': \"You are a content policy checker. Analyze the given COMMENT, RULE, and SUBREDDIT context below. Output exactly one word:\\n- 'complies' if the comment follows the subreddit rules, or\\n- 'violates' if it breaks them.\\n\\nCOMMENT: unethical but... make a SS# but state name and address and all perfectly.  If the IRS asks, just say that's the number you got, let the IRS sort if out for you.\\nRULE: No legal advice: Do not offer or request legal advice.\\nSUBREDDIT: personalfinance\",\n",
       "   'role': 'user'},\n",
       "  {'content': 'violates', 'role': 'assistant'}]}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_subset_chat['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mx3Waetkm6xm",
   "metadata": {
    "id": "mx3Waetkm6xm"
   },
   "source": [
    "##  <font color = 'indianred'> **Filter Longer sequences**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Uc70zod4x-X5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_length(example):\n",
    "    # Find the first user message\n",
    "    text_to_check = None\n",
    "    for msg in example.get(\"messages\", []):\n",
    "        if msg.get(\"role\") == \"user\":\n",
    "            text_to_check = msg.get(\"content\", \"\").strip()\n",
    "            break\n",
    "\n",
    "    # Return False if there's no user message or empty text\n",
    "    if not text_to_check:\n",
    "        return False\n",
    "\n",
    "    # Tokenize the text and check length\n",
    "    encoding = tokenizer.encode(text_to_check)\n",
    "    return len(encoding) <= 1024\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeg1drKwB3w8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be596644724d4360a97836329bb3a9bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/1623 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "922cd56b2d8f4d7d87c49cab43966190",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc623034aeae4e0f8f0db33cb8e67901",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filtered_data_subset_chat = DatasetDict({\n",
    "    split: data_subset_chat[split].filter(check_length)\n",
    "    for split in data_subset_chat.keys()\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attaIOVAC-2J",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['messages'],\n",
       "        num_rows: 1623\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['messages'],\n",
       "        num_rows: 203\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['messages'],\n",
       "        num_rows: 203\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data_subset_chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "u9EFpV4cDE8p",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'content': \"You are a content policy checker. Analyze the given COMMENT, RULE, and SUBREDDIT context below. Output exactly one word:\\n- 'complies' if the comment follows the subreddit rules, or\\n- 'violates' if it breaks them.\\n\\nCOMMENT: unethical but... make a SS# but state name and address and all perfectly.  If the IRS asks, just say that's the number you got, let the IRS sort if out for you.\\nRULE: No legal advice: Do not offer or request legal advice.\\nSUBREDDIT: personalfinance\",\n",
       "   'role': 'user'},\n",
       "  {'content': 'violates', 'role': 'assistant'}]}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data_subset_chat['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oc8yi_GQDKqA",
   "metadata": {
    "id": "oc8yi_GQDKqA"
   },
   "source": [
    "##  <font color = 'indianred'> **Push Dataset to Hub**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eYtGScTRDWIK",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95836b1d153f411089dc67f25ed701c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ? shards/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d0a441171044d6b8b5c440bfd9a78b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "942f8da05a444082ab4ca1c02e73f755",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34df75dc18c4418ea36717753aef041d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload               : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a053121ddc6d41e7964fefcf4f5b78b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "                              : 100%|##########|  258kB /  258kB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aed4936198374325b09ac865bc51afd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ? shards/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47261ffae9b74a93aabcfd4c64e4433d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "451bec6d286c4a2cb4c1834dc20d8ac9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f99f354ac000496f94a5799658f08e6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload               : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f00cadbf06a41a48a4e0236f176b553",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "                              : 100%|##########| 33.6kB / 33.6kB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af237e0f58b04e03b7d84ece9a84c4b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ? shards/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0592f0d9fcd497eba4a2235d38ca45e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12b4e6e5e1264f048af71522348f4d4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad5b1d8c318542259156a60b4c318767",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload               : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a8d5169a58040918658a3b270d0fdb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "                              : 100%|##########| 34.0kB / 34.0kB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d539feae2e54fb989bbee29352f1f5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/540 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/Ron00769/jigsaw_binary_subset_chat/commit/01485c6231dd43778869b041351f3102bd7be278', commit_message='Upload dataset', commit_description='', oid='01485c6231dd43778869b041351f3102bd7be278', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/Ron00769/jigsaw_binary_subset_chat', endpoint='https://huggingface.co', repo_type='dataset', repo_id='Ron00769/jigsaw_binary_subset_chat'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data_subset_chat.push_to_hub(\n",
    "    \"Ron00769/jigsaw_binary_subset_chat\",\n",
    "    private=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "O7-5sm2uBTN_",
   "metadata": {
    "id": "O7-5sm2uBTN_"
   },
   "source": [
    "#  <font color = 'indianred'> **Model Training**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2a39fc-6d87-43ca-8a6e-7129bd8214f1",
   "metadata": {
    "id": "cc2a39fc-6d87-43ca-8a6e-7129bd8214f1"
   },
   "source": [
    "##  <font color = 'indianred'> **Download pre-trained model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Uh43-6J8LWlS",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_appropriate_dtype():\n",
    "    if torch.cuda.is_available() and torch.cuda.get_device_capability(0) >= (8, 0):\n",
    "        return torch.bfloat16\n",
    "    return torch.float16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CBvrKgAeLZJV",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.bfloat16"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_data_type = get_appropriate_dtype()\n",
    "torch_data_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "g46jiz0vLSGk",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "  load_in_4bit=True,\n",
    "  bnb_4bit_quant_type=\"nf4\",\n",
    "  bnb_4bit_use_double_quant=True,\n",
    "  bnb_4bit_compute_dtype=torch_data_type,\n",
    "  bnb_4bit_quant_storage=torch_data_type,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58babf85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c2262ba78f94235920da6d5d032b4a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/838 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9290d05688a7413c98b0a69e3e8d1129",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/24.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10f1d8f11eab44e4b367b925ce5407f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63d2ec3323eb4d3a801d27b2f76910c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/241M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7bfe7334a0143c59bec08c212c5ae74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35baef925570470bb4ea48b94a9145ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55bc1f46e66d4e1da2259b14ddb5897c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/187 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(checkpoint,\n",
    "                                             quantization_config=bnb_config,\n",
    "                                             torch_dtype=torch_data_type,\n",
    "                                             trust_remote_code=True,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GS6SSVBUpFz1",
   "metadata": {
    "id": "GS6SSVBUpFz1"
   },
   "source": [
    "##  <font color = 'indianred'> **PEFT Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DTgloiC4pps7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gemma2ForCausalLM(\n",
       "  (model): Gemma2Model(\n",
       "    (embed_tokens): Embedding(256000, 2304, padding_idx=0)\n",
       "    (layers): ModuleList(\n",
       "      (0-25): 26 x Gemma2DecoderLayer(\n",
       "        (self_attn): Gemma2Attention(\n",
       "          (q_proj): Linear4bit(in_features=2304, out_features=2048, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=2304, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=2304, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=2048, out_features=2304, bias=False)\n",
       "        )\n",
       "        (mlp): Gemma2MLP(\n",
       "          (gate_proj): Linear4bit(in_features=2304, out_features=9216, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=2304, out_features=9216, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=9216, out_features=2304, bias=False)\n",
       "          (act_fn): GELUTanh()\n",
       "        )\n",
       "        (input_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
       "        (post_attention_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
       "        (pre_feedforward_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
       "        (post_feedforward_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
       "    (rotary_emb): Gemma2RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2304, out_features=256000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eq60NtZWszfC",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_linear_layers(model):\n",
    "    \"\"\"\n",
    "    Extracts the unique names of Linear layers from a model.\n",
    "\n",
    "    Args:\n",
    "    model (nn.Module): The model from which to extract Linear layer names.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of unique names of Linear layers.\n",
    "    \"\"\"\n",
    "    # Convert the model's modules to string\n",
    "    model_modules = str(model.modules)\n",
    "    # Pattern to extract names of Linear layers\n",
    "    pattern = r'\\((\\w+)\\): Linear'\n",
    "    # Find all occurrences of the pattern\n",
    "    linear_layer_names = re.findall(pattern, model_modules)\n",
    "    print(linear_layer_names)\n",
    "    # Get unique names using a set, then convert back to list\n",
    "    target_modules = list(set(linear_layer_names))\n",
    "    return target_modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WOiU0qHIpaL-",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj', 'lm_head']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['k_proj',\n",
       " 'o_proj',\n",
       " 'v_proj',\n",
       " 'lm_head',\n",
       " 'down_proj',\n",
       " 'gate_proj',\n",
       " 'up_proj',\n",
       " 'q_proj']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_linear_layers(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ixm-x8g5DLh-",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "<TaskType.CAUSAL_LM: 'CAUSAL_LM'>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TaskType.CAUSAL_LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PF49fLAjphS-",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    r=128,\n",
    "    lora_alpha=256,\n",
    "    lora_dropout=0.01,\n",
    "    target_modules = ['v_proj',  'q_proj',  'up_proj', 'o_proj', 'down_proj', 'gate_proj','k_proj'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Jwwp80UgmLjr",
   "metadata": {
    "id": "Jwwp80UgmLjr"
   },
   "source": [
    "## <font color = 'indianred'> **Training Arguments**</font>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hIXDbzK8O4x9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory where model checkpoints will be saved\n",
    "model_folder = base_folder/'models/jigsaw/decoder_with_instruction_language_head'\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "model_folder.mkdir(exist_ok=True, parents=True)\n",
    "run_name= 'jigsaw_inst_exp_lmh_gemma_inst'\n",
    "\n",
    "use_fp16 = torch_data_type == torch.float16\n",
    "use_bf16 = torch_data_type == torch.bfloat16\n",
    "\n",
    "# Configure training parameters\n",
    "training_args = SFTConfig(\n",
    "    seed = 42,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_length = 1024,\n",
    "    packing = False,\n",
    "    assistant_only_loss=True,\n",
    "\n",
    "    # Training-specific configurations\n",
    "    num_train_epochs=2,  # Total number of training epochs\n",
    "    per_device_train_batch_size=8, # Number of samples per training batch for each device\n",
    "    per_device_eval_batch_size=8,  # Number of samples per evaluation batch for each device\n",
    "    gradient_accumulation_steps=2,\n",
    "    gradient_checkpointing=True,\n",
    "    gradient_checkpointing_kwargs={\"use_reentrant\":False},\n",
    "    # torch_empty_cache_steps=5,\n",
    "    weight_decay=0.0,  # Apply L2 regularization to prevent overfitting\n",
    "    learning_rate=1e-5,  # Step size for the optimizer during training\n",
    "    optim='adamw_torch',  # Optimizer,\n",
    "\n",
    "    # Checkpoint saving and model evaluation settings\n",
    "    output_dir=str(model_folder),  # Directory to save model checkpoints\n",
    "    eval_strategy='steps',  # Evaluate model at specified step intervals\n",
    "    eval_steps=20,  # Perform evaluation every 10 training steps\n",
    "    save_strategy=\"steps\",  # Save model checkpoint at specified step intervals\n",
    "    save_steps=20,  # Save a model checkpoint every 10 training steps\n",
    "    load_best_model_at_end=True,  # Reload the best model at the end of training\n",
    "    save_total_limit=2,  # Retain only the best and the most recent model checkpoints\n",
    "    # Use 'accuracy' as the metric to determine the best model\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,  # A model is 'better' if its accuracy is higher\n",
    "\n",
    "\n",
    "    # Experiment logging configurations (commented out in this example)\n",
    "    logging_strategy='steps',\n",
    "    logging_steps=20,\n",
    "    report_to='wandb',  # Log metrics and results to Weights & Biases platform\n",
    "    run_name= run_name,  # Experiment name for Weights & Biases\n",
    "\n",
    "    # Precision settings determined based on GPU capability\n",
    "    fp16=use_fp16 ,  # Set True if torch_data_type is torch.float16\n",
    "    bf16=use_bf16,  # Set True if torch_data_type is torch.bfloat16\n",
    "    tf32=False,  # Disable tf32 unless you want to use Ampere specific optimization\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exUBN-oC51xA",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If gradient checkpointing is enabled, configure relevant settings\n",
    "if training_args.gradient_checkpointing:\n",
    "    model.config.use_cache = False  # Disable caching for compatibility\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "J_hMcxgrFNyT",
   "metadata": {
    "id": "J_hMcxgrFNyT"
   },
   "source": [
    "##  <font color = 'indianred'> **Initialize Trainer**</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iEtX_DvoAoTn",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "382d4b84d1754a96a98d2960ff84717b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/1623 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f10b37d3b4642899b86f0565d300dad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating train dataset:   0%|          | 0/1623 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccc728d1412546caac421461f97f2165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing eval dataset:   0%|          | 0/203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faa509a6ef2144d09472cd962c29cd50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating eval dataset:   0%|          | 0/203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=filtered_data_subset_chat['train'],\n",
    "    eval_dataset=filtered_data_subset_chat['valid'],\n",
    "    peft_config=peft_config,\n",
    "    processing_class=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "D2GAewO8WdsA",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = trainer.get_train_dataloader()\n",
    "batch = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5r2rd1lFQVot",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[108,   2, 108,  ...,   0,   0,   0],\n",
       "         [108,   2, 108,  ...,   0,   0,   0],\n",
       "         [108,   2, 108,  ...,   0,   0,   0],\n",
       "         ...,\n",
       "         [108,   2, 108,  ...,   0,   0,   0],\n",
       "         [108,   2, 108,  ...,   0,   0,   0],\n",
       "         [108,   2, 108,  ...,   0,   0,   0]], device='cuda:0'),\n",
       " 'labels': tensor([[-100, -100, -100,  ..., -100, -100, -100],\n",
       "         [-100, -100, -100,  ..., -100, -100, -100],\n",
       "         [-100, -100, -100,  ..., -100, -100, -100],\n",
       "         ...,\n",
       "         [-100, -100, -100,  ..., -100, -100, -100],\n",
       "         [-100, -100, -100,  ..., -100, -100, -100],\n",
       "         [-100, -100, -100,  ..., -100, -100, -100]], device='cuda:0'),\n",
       " 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Etswu7RhQU3-",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 108,    2,  108,  106, 1645], device='cuda:0')\n",
      "\n",
      "<bos>\n",
      "<start_of_turn>user\n",
      "tensor([-100, -100, -100, -100, -100], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(batch['input_ids'][0][0:5])\n",
    "print(tokenizer.decode(batch['input_ids'][0][0:5]))\n",
    "print(batch['labels'][0][0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZjxJI_v1QXV_",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228\n",
      "228\n"
     ]
    }
   ],
   "source": [
    "print(len(batch['input_ids'][0]))\n",
    "print(len(batch['labels'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eoogERmSQabX",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 108,    2,  108,  106, 1645], device='cuda:0')\n",
      "\n",
      "<bos>\n",
      "<start_of_turn>user\n",
      "tensor([-100, -100, -100, -100, -100], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(batch['input_ids'][0][0:5])\n",
    "print(tokenizer.decode(batch['input_ids'][0][0:5]))\n",
    "print(batch['labels'][0][0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AUQLpzoPWv9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INPUTS\n",
      "--------------------------------------------------------------------------------\n",
      "tensor([ 72364, 109564,    108,    107,    108,    106,   2516,    108,  49515,\n",
      "          1204,    107,    108,      0,      0], device='cuda:0')\n",
      "\n",
      "LABELS\n",
      "--------------------------------------------------------------------------------\n",
      "tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100, 49515,  1204,\n",
      "         -100,  -100,  -100,  -100], device='cuda:0')\n",
      "\n",
      "Tokens\n",
      "--------------------------------------------------------------------------------\n",
      " Showerthoughts\n",
      "<end_of_turn>\n",
      "<start_of_turn>model\n",
      "violates<end_of_turn>\n",
      "<pad><pad>\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nINPUTS\")\n",
    "print(f\"{'-'*80}\")\n",
    "print(batch['input_ids'][0][106:120])\n",
    "print(f\"\\nLABELS\")\n",
    "print(f\"{'-'*80}\")\n",
    "print(batch['labels'][0][106:120])\n",
    "print(f\"\\nTokens\")\n",
    "print(f\"{'-'*80}\")\n",
    "print(tokenizer.decode(batch['input_ids'][0][106:120]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yH0UXC40QeRt",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_loss_masking(tokenizer, trainer, num_samples=3):\n",
    "    \"\"\"\n",
    "    Verify which tokens contribute to loss (labels != -100)\n",
    "    for a few samples from the training dataloader.\n",
    "    \"\"\"\n",
    "    dataloader = trainer.get_train_dataloader()\n",
    "    batch = next(iter(dataloader))\n",
    "\n",
    "    for i in range(min(num_samples, len(batch[\"input_ids\"]))):\n",
    "        input_ids = batch[\"input_ids\"][i]\n",
    "        labels = batch[\"labels\"][i]\n",
    "\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Sample {i+1}\")\n",
    "        print(f\"{'='*80}\")\n",
    "\n",
    "        # Decode full sequence for reference\n",
    "        full_text = tokenizer.decode(input_ids, skip_special_tokens=False)\n",
    "        pprint(f\"\\nFull text:\\n{full_text}\")\n",
    "\n",
    "        # Identify tokens used for loss\n",
    "        loss_token_indices = (labels != -100).nonzero(as_tuple=True)[0]\n",
    "\n",
    "        if len(loss_token_indices) == 0:\n",
    "            print(\"All tokens masked â€” no loss will be calculated.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nTokens contributing to loss ({len(loss_token_indices)} total):\")\n",
    "        print(f\"{'-'*80}\")\n",
    "        print(f\"{'Index':<8} {'Token ID':<10} {'Token Text'}\")\n",
    "        print(f\"{'-'*80}\")\n",
    "\n",
    "        for idx in loss_token_indices.tolist():\n",
    "            token_id = input_ids[idx].item()\n",
    "            token_text = tokenizer.decode([token_id], skip_special_tokens=False)\n",
    "            print(f\"{idx:<8} {token_id:<10} {repr(token_text)}\")\n",
    "\n",
    "        print(f\"{'-'*80}\")\n",
    "        print(f\"Percentage of tokens used for loss: {len(loss_token_indices)/len(labels)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46VIJDTZQiTw",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Sample 1\n",
      "================================================================================\n",
      "('\\n'\n",
      " 'Full text:\\n'\n",
      " '\\n'\n",
      " '<bos>\\n'\n",
      " '<start_of_turn>user\\n'\n",
      " 'You are a content policy checker. Analyze the given COMMENT, RULE, and '\n",
      " 'SUBREDDIT context below. Output exactly one word:\\n'\n",
      " \"- 'complies' if the comment follows the subreddit rules, or\\n\"\n",
      " \"- 'violates' if it breaks them.\\n\"\n",
      " '\\n'\n",
      " 'COMMENT: naughty holes wait you there http://by.ix-cafe.com/4j3pu\\n'\n",
      " 'RULE: No Advertising: Spam, referral links, unsolicited advertising, and '\n",
      " 'promotional content are not allowed.\\n'\n",
      " 'SUBREDDIT: Showerthoughts\\n'\n",
      " '<end_of_turn>\\n'\n",
      " '<start_of_turn>model\\n'\n",
      " 'violates<end_of_turn>\\n'\n",
      " '<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>')\n",
      "\n",
      "Tokens contributing to loss (2 total):\n",
      "--------------------------------------------------------------------------------\n",
      "Index    Token ID   Token Text\n",
      "--------------------------------------------------------------------------------\n",
      "114      49515      'viol'\n",
      "115      1204       'ates'\n",
      "--------------------------------------------------------------------------------\n",
      "Percentage of tokens used for loss: 0.88%\n",
      "\n",
      "================================================================================\n",
      "Sample 2\n",
      "================================================================================\n",
      "('\\n'\n",
      " 'Full text:\\n'\n",
      " '\\n'\n",
      " '<bos>\\n'\n",
      " '<start_of_turn>user\\n'\n",
      " 'You are a content policy checker. Analyze the given COMMENT, RULE, and '\n",
      " 'SUBREDDIT context below. Output exactly one word:\\n'\n",
      " \"- 'complies' if the comment follows the subreddit rules, or\\n\"\n",
      " \"- 'violates' if it breaks them.\\n\"\n",
      " '\\n'\n",
      " \"COMMENT: Here's my referral link, thanks and enjoy!: \"\n",
      " 'https://www.regions.referlive.com/newcustform/364X5F0XAAAB/14/0840084ZAHDWQ3N\\n'\n",
      " 'RULE: No Advertising: Spam, referral links, unsolicited advertising, and '\n",
      " 'promotional content are not allowed.\\n'\n",
      " 'SUBREDDIT: churning\\n'\n",
      " '<end_of_turn>\\n'\n",
      " '<start_of_turn>model\\n'\n",
      " 'violates<end_of_turn>\\n'\n",
      " '<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>')\n",
      "\n",
      "Tokens contributing to loss (2 total):\n",
      "--------------------------------------------------------------------------------\n",
      "Index    Token ID   Token Text\n",
      "--------------------------------------------------------------------------------\n",
      "147      49515      'viol'\n",
      "148      1204       'ates'\n",
      "--------------------------------------------------------------------------------\n",
      "Percentage of tokens used for loss: 0.88%\n"
     ]
    }
   ],
   "source": [
    "# Call this after creating your trainer\n",
    "verify_loss_masking(tokenizer, trainer, num_samples=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "IGDxeCI38uqm",
   "metadata": {
    "id": "IGDxeCI38uqm"
   },
   "source": [
    "## <font color = 'indianred'> **Setup WandB**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "S8CaRySh81mi",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_PROJECT=jigsaw_inst_language_head2025\n"
     ]
    }
   ],
   "source": [
    "%env WANDB_PROJECT = jigsaw_inst_language_head2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ty027fT4DFGn",
   "metadata": {
    "id": "ty027fT4DFGn"
   },
   "source": [
    "##  <font color = 'indianred'> **Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RVurPfZHvOKK",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 1}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20251103_023627-mk7j6o95</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ronchaudhuri29-the-university-of-texas-at-dallas/jigsaw_inst_language_head2025/runs/mk7j6o95' target=\"_blank\">jigsaw_inst_exp_lmh_gemma_inst</a></strong> to <a href='https://wandb.ai/ronchaudhuri29-the-university-of-texas-at-dallas/jigsaw_inst_language_head2025' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ronchaudhuri29-the-university-of-texas-at-dallas/jigsaw_inst_language_head2025' target=\"_blank\">https://wandb.ai/ronchaudhuri29-the-university-of-texas-at-dallas/jigsaw_inst_language_head2025</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ronchaudhuri29-the-university-of-texas-at-dallas/jigsaw_inst_language_head2025/runs/mk7j6o95' target=\"_blank\">https://wandb.ai/ronchaudhuri29-the-university-of-texas-at-dallas/jigsaw_inst_language_head2025/runs/mk7j6o95</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='204' max='204' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [204/204 07:10, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Entropy</th>\n",
       "      <th>Num Tokens</th>\n",
       "      <th>Mean Token Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.659700</td>\n",
       "      <td>0.342797</td>\n",
       "      <td>2.076317</td>\n",
       "      <td>45591.000000</td>\n",
       "      <td>0.766026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.360100</td>\n",
       "      <td>0.326619</td>\n",
       "      <td>2.045369</td>\n",
       "      <td>91228.000000</td>\n",
       "      <td>0.808494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.283300</td>\n",
       "      <td>0.329332</td>\n",
       "      <td>1.955427</td>\n",
       "      <td>137564.000000</td>\n",
       "      <td>0.826923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.258100</td>\n",
       "      <td>0.297278</td>\n",
       "      <td>1.956674</td>\n",
       "      <td>183266.000000</td>\n",
       "      <td>0.858173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.244600</td>\n",
       "      <td>0.275228</td>\n",
       "      <td>1.957899</td>\n",
       "      <td>229401.000000</td>\n",
       "      <td>0.877404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.204500</td>\n",
       "      <td>0.264178</td>\n",
       "      <td>1.953300</td>\n",
       "      <td>273874.000000</td>\n",
       "      <td>0.879808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.206400</td>\n",
       "      <td>0.255462</td>\n",
       "      <td>1.957341</td>\n",
       "      <td>320139.000000</td>\n",
       "      <td>0.882212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.186200</td>\n",
       "      <td>0.287796</td>\n",
       "      <td>1.956602</td>\n",
       "      <td>365895.000000</td>\n",
       "      <td>0.877404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>0.270112</td>\n",
       "      <td>1.958214</td>\n",
       "      <td>410590.000000</td>\n",
       "      <td>0.867788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.172200</td>\n",
       "      <td>0.265974</td>\n",
       "      <td>1.960398</td>\n",
       "      <td>457521.000000</td>\n",
       "      <td>0.877404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    # Your code that may cause a CUDA out-of-memory error\n",
    "    # Example: trainer.train() or other GPU intensive operations\n",
    "    # lora_model.config.use_cache = False\n",
    "    trainer.train()\n",
    "except RuntimeError as e:\n",
    "    if 'CUDA out of memory' in str(e):\n",
    "        print(\"CUDA out of memory error detected. Freeing GPU memory.\")\n",
    "        free_gpu_memory()\n",
    "        # Optionally, you can retry the operation here after freeing up memory\n",
    "        # Example retry:\n",
    "        # trainer.train()\n",
    "    else:\n",
    "        raise e\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4IDg8Hu1Qpwl",
   "metadata": {
    "id": "4IDg8Hu1Qpwl"
   },
   "source": [
    "##  <font color = 'indianred'> **6.6 Push best checkpoint to Hub**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "W0ZwbDiZz8Ol",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_checkpoint_step = trainer.state.best_model_checkpoint.split('-')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1HrLydYRz8-v",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'140'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_checkpoint_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e362a7fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content/drive/MyDrive/data/models/jigsaw/decoder_with_instruction_language_head/checkpoint-140'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = str(model_folder/f'checkpoint-{best_model_checkpoint_step}')\n",
    "checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rZS48zbuQvO1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80c509b4e79548f2aa306daf0986d8ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76a851d1e1ce4c018db816a9d4073de4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload               : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4838319bbb9c42a5a164779fcf37a477",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...kpoint-140/tokenizer.json: 100%|##########| 34.4MB / 34.4MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "572bc89e39514d958929737212917c3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...point-140/tokenizer.model: 100%|##########| 4.24MB / 4.24MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81218f631973499c806553dbc56d7da7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...eckpoint-140/optimizer.pt:   0%|          |  569kB / 1.33GB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f85d988a77d47bcb2b49d1c91d9cfab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...adapter_model.safetensors:   0%|          | 43.0kB /  665MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd89e1098a1a476b8b6cd91f09dc0cac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...eckpoint-140/scheduler.pt: 100%|##########| 1.47kB / 1.47kB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19029ffe4a374ebbae40346f50f8ee0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...ckpoint-140/rng_state.pth:  77%|#######7  | 11.3kB / 14.6kB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d99325cab8974f38acf25e9e8a4c95df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...int-140/training_args.bin:   6%|6         |   400B / 6.42kB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/Ron00769/jigsaw_binary_instr_lm_head/commit/57b3f7be6faa47c3dac5095ebcc7a8ee1c850040', commit_message='Upload folder using huggingface_hub', commit_description='', oid='57b3f7be6faa47c3dac5095ebcc7a8ee1c850040', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Ron00769/jigsaw_binary_instr_lm_head', endpoint='https://huggingface.co', repo_type='model', repo_id='Ron00769/jigsaw_binary_instr_lm_head'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Create the repository\n",
    "repo_id=\"Ron00769/jigsaw_binary_instr_lm_head\"\n",
    "create_repo(\n",
    "    repo_id=repo_id,\n",
    "    repo_type=\"model\",\n",
    "    private=False,  # Set to True if you want it private\n",
    "    exist_ok=True   # Won't error if repo already exists\n",
    ")\n",
    "\n",
    "# Step 2: Upload the folder\n",
    "api = HfApi()\n",
    "api.upload_folder(\n",
    "    folder_path=checkpoint,\n",
    "    repo_id=repo_id,\n",
    "    repo_type=\"model\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "w4RDWmSOhTmL",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/entropy</td><td>â–ˆâ–†â–â–â–â–â–â–â–â–</td></tr><tr><td>eval/loss</td><td>â–ˆâ–‡â–‡â–„â–ƒâ–‚â–â–„â–‚â–‚</td></tr><tr><td>eval/mean_token_accuracy</td><td>â–â–„â–…â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆ</td></tr><tr><td>eval/num_tokens</td><td>â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ</td></tr><tr><td>eval/runtime</td><td>â–â–ˆâ–ˆâ–„â–â–‡â–ƒâ–„â–‚â–</td></tr><tr><td>eval/samples_per_second</td><td>â–ˆâ–â–â–…â–ˆâ–‚â–†â–…â–‡â–ˆ</td></tr><tr><td>eval/steps_per_second</td><td>â–ˆâ–â–â–…â–ˆâ–‚â–†â–…â–‡â–ˆ</td></tr><tr><td>train/entropy</td><td>â–ƒâ–ˆâ–„â–â–ƒâ–‚â–‚â–‚â–â–ƒ</td></tr><tr><td>train/epoch</td><td>â–â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–…â–…â–†â–†â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>train/global_step</td><td>â–â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–…â–…â–†â–†â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>+5</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/entropy</td><td>1.9604</td></tr><tr><td>eval/loss</td><td>0.26597</td></tr><tr><td>eval/mean_token_accuracy</td><td>0.8774</td></tr><tr><td>eval/num_tokens</td><td>457521</td></tr><tr><td>eval/runtime</td><td>4.7949</td></tr><tr><td>eval/samples_per_second</td><td>42.337</td></tr><tr><td>eval/steps_per_second</td><td>5.422</td></tr><tr><td>total_flos</td><td>8293557405040128.0</td></tr><tr><td>train/entropy</td><td>1.99932</td></tr><tr><td>train/epoch</td><td>2</td></tr><tr><td>+10</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">jigsaw_inst_exp_lmh_gemma_inst</strong> at: <a href='https://wandb.ai/ronchaudhuri29-the-university-of-texas-at-dallas/jigsaw_inst_language_head2025/runs/mk7j6o95' target=\"_blank\">https://wandb.ai/ronchaudhuri29-the-university-of-texas-at-dallas/jigsaw_inst_language_head2025/runs/mk7j6o95</a><br> View project at: <a href='https://wandb.ai/ronchaudhuri29-the-university-of-texas-at-dallas/jigsaw_inst_language_head2025' target=\"_blank\">https://wandb.ai/ronchaudhuri29-the-university-of-texas-at-dallas/jigsaw_inst_language_head2025</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251103_023627-mk7j6o95/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
