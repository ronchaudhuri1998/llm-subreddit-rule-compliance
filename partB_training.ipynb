{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fj41POPjrtzA",
   "metadata": {
    "id": "fj41POPjrtzA"
   },
   "source": [
    "# <font color = 'indianred'> **1. Setting up the Environment** </font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d54de23-80e9-4e1b-816c-6f6916c92836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/62.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/16.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9.8/16.6 MB\u001b[0m \u001b[31m295.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m256.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m125.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.4 which is incompatible.\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.4 which is incompatible.\n",
      "cupy-cuda12x 13.3.0 requires numpy<2.3,>=1.22, but you have numpy 2.3.4 which is incompatible.\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.4 which is incompatible.\n",
      "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.4 which is incompatible.\n",
      "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.3.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m116.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m506.8/506.8 kB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m423.1/423.1 kB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pylibcudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\n",
      "cudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mFound existing installation: tensorflow 2.19.0\n",
      "Uninstalling tensorflow-2.19.0:\n",
      "  Would remove:\n",
      "    /usr/local/bin/import_pb_to_tensorboard\n",
      "    /usr/local/bin/saved_model_cli\n",
      "    /usr/local/bin/tensorboard\n",
      "    /usr/local/bin/tf_upgrade_v2\n",
      "    /usr/local/bin/tflite_convert\n",
      "    /usr/local/bin/toco\n",
      "    /usr/local/lib/python3.12/dist-packages/tensorflow-2.19.0.dist-info/*\n",
      "    /usr/local/lib/python3.12/dist-packages/tensorflow/*\n",
      "Proceed (Y/n)? Y\n",
      "  Successfully uninstalled tensorflow-2.19.0\n"
     ]
    }
   ],
   "source": [
    "# If in Colab, then import the drive module from google.colab\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "  !pip install numpy -U -qq\n",
    "  !pip install transformers evaluate wandb datasets accelerate trl peft bitsandbytes -U -qq\n",
    "  !pip uninstall tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cYPc8606XOHv",
   "metadata": {
    "id": "cYPc8606XOHv"
   },
   "source": [
    " <Font size = 5 color = 'indianred'>**Restart the session before moving onto next cell**\n",
    "> Runtime- Restart Session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1Kcz9H4QsW6_",
   "metadata": {
    "id": "1Kcz9H4QsW6_"
   },
   "source": [
    "<font color = 'indianred'> *Load Libraries* </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "yC6lJrxYvxeF",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard python libraries\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Union, Optional, Tuple\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import joblib\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import re\n",
    "import gc\n",
    "import time\n",
    "\n",
    "# Data Science librraies\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "# Pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Huggingface Librraies\n",
    "import evaluate\n",
    "from datasets import load_dataset, DatasetDict, Dataset, ClassLabel\n",
    "from trl import SFTConfig, SFTTrainer\n",
    "from transformers import (\n",
    "    set_seed,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    AutoConfig,\n",
    "    BitsAndBytesConfig,\n",
    ")\n",
    "from peft import (\n",
    "    TaskType,\n",
    "    LoraConfig,\n",
    "    prepare_model_for_kbit_training,\n",
    "    get_peft_model,\n",
    "    AutoPeftModelForCausalLM,\n",
    "    PeftConfig\n",
    ")\n",
    "from pprint import pprint\n",
    "# Logging and secrets\n",
    "from huggingface_hub import login, HfApi, create_repo\n",
    "from google.colab import userdata\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "lkR7CvSxopiE",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# Determine the storage location based on the execution environment\n",
    "# If running on Google Colab, use Google Drive as storage\n",
    "# CHANGE FOLDERS TO WHERE YOU WANT TO SAVE DATA AND MODELS\n",
    "\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    from google.colab import drive  # Import Google Drive mounting utility\n",
    "    drive.mount('/content/drive')  # Mount Google Drive\n",
    "\n",
    "    # Set base folder path for storing data on Google Drive\n",
    "    base_folder= Path('/content/drive/MyDrive/data')\n",
    "\n",
    "# If running locally, specify a different path\n",
    "else:\n",
    "    # Set base folder path for storing data on local machine\n",
    "    base_folder= Path('/Users/ronchaudhuri/Documents/Models/Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "MMk63r7U_G8t",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_api_key = userdata.get('WANDB_API_KEY')\n",
    "hf_token = userdata.get('HF_Token')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "k4jv63G1X9Uz",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully logged in to Hugging Face!\n"
     ]
    }
   ],
   "source": [
    "if hf_token:\n",
    "    # Log in to Hugging Face\n",
    "    login(token=hf_token)\n",
    "    print(\"Successfully logged in to Hugging Face!\")\n",
    "else:\n",
    "    print(\"Hugging Face token not found in notebook secrets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "N4YKVvENX_bV",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
      "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mronchaudhuri29\u001b[0m (\u001b[33mronchaudhuri29-the-university-of-texas-at-dallas\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully logged in to WANDB!\n"
     ]
    }
   ],
   "source": [
    "if wandb_api_key:\n",
    "  wandb.login(key=wandb_api_key)\n",
    "  print(\"Successfully logged in to WANDB!\")\n",
    "else:\n",
    "    print(\"WANDB key not found in notebook secrets.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b906904c-8f24-4de0-8e07-720863e8cd99",
   "metadata": {
    "id": "b906904c-8f24-4de0-8e07-720863e8cd99"
   },
   "source": [
    "# <font color = 'indianred'> **2. Load Data set**\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "kEy8Zj7CYDZC",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df\",\n  \"rows\": 2029,\n  \"fields\": [\n    {\n      \"column\": \"row_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 585,\n        \"min\": 0,\n        \"max\": 2028,\n        \"num_unique_values\": 2029,\n        \"samples\": [\n          1356,\n          984,\n          859\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"body\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1869,\n        \"samples\": [\n          \"Everything explain in 90 seconds https://www.youtube.com/watch?v=GIEwd837k5s\",\n          \"How do you go about spoofing without getting caught and banned?\",\n          \"...So you're telling me that I could go graverobbing and make 1.4k a pop?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rule\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"No legal advice: Do not offer or request legal advice.\",\n          \"No Advertising: Spam, referral links, unsolicited advertising, and promotional content are not allowed.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"subreddit\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"Android\",\n          \"spacex\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"positive_example_1\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 458,\n        \"samples\": [\n          \"Yes, but she's reported me before. FBI can just subpena. It was also reported by the same person twice. So the FBI will definitely subpoena it. \\n\\nI just need to find people to snitch on so I can get out of it. \",\n          \" she is  for free  therein  masturbate  http://annon.link/qiit\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"positive_example_2\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 461,\n        \"samples\": [\n          \"This study is propaganda.  Yes, background checks are required in every state.  But this study is saying, \\\"45 states don't require background checks!\\\"  And that is only true in the sense that, the states themselves *don't need to* require background checks, since Federal law already does require them, and applies even to transactions that occur wholly within a single state.  It's just straight dishonest, afaict.\",\n          \"He signed NDAA. Treason. Any jury of people aware of constitutional law would convict him.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"negative_example_1\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 489,\n        \"samples\": [\n          \"SD [Stream SD Mobile Supported Channel 2 EN](http://gern.co/content/click-here-watch-uefa-champions-league-live-streaming-link-online-free-0)\\n\\n\\nHD\\n\\n\\nDirect to Video streamSD [Stream SD Mobile Supported Channel 2 EN](http://gern.co/content/click-here-watch-uefa-champions-league-live-streaming-link-online-free-0)\\n\\n\\nHD\\n\\n\\nDirect to Video stream\",\n          \"[WEB ONLY] [AdBlock OK] SD - ENGLISH [Stream #1](http://www.goindexsport.com/AIK---Bala.html) \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"negative_example_2\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 493,\n        \"samples\": [\n          \"[Mobile Utilities](https://play.google.com/store/apps/details?id=andromart.mobileutilities) would probably contain a few things that you (and most students around) would find extremely useful. \",\n          \"We will be launching our stable not Niantic server straining Pokemon finder on Monday....will look like what most are used to..stay tuned or on [Twitter](https://twitter.com/pokefindernow)\\nOn with the fun again! [Pokefinder](www.pokefindernow.com)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rule_violation\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-27edc956-803d-43bc-9c63-67487054c243\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>body</th>\n",
       "      <th>rule</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>positive_example_1</th>\n",
       "      <th>positive_example_2</th>\n",
       "      <th>negative_example_1</th>\n",
       "      <th>negative_example_2</th>\n",
       "      <th>rule_violation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Banks don't want you to know this! Click here ...</td>\n",
       "      <td>No Advertising: Spam, referral links, unsolici...</td>\n",
       "      <td>Futurology</td>\n",
       "      <td>If you could tell your younger self something ...</td>\n",
       "      <td>hunt for lady for jack off in neighbourhood ht...</td>\n",
       "      <td>Watch Golden Globe Awards 2017 Live Online in ...</td>\n",
       "      <td>DOUBLE CEE x BANDS EPPS - \"BIRDS\"\\n\\nDOWNLOAD/...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>SD Stream [ ENG Link 1] (http://www.sportsstre...</td>\n",
       "      <td>No Advertising: Spam, referral links, unsolici...</td>\n",
       "      <td>soccerstreams</td>\n",
       "      <td>[I wanna kiss you all over! Stunning!](http://...</td>\n",
       "      <td>LOLGA.COM is One of the First Professional Onl...</td>\n",
       "      <td>#Rapper \\nüö®Straight Outta Cross Keys SC üö®YouTu...</td>\n",
       "      <td>[15 Amazing Hidden Features Of Google Search Y...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Lol. Try appealing the ban and say you won't d...</td>\n",
       "      <td>No legal advice: Do not offer or request legal...</td>\n",
       "      <td>pcmasterrace</td>\n",
       "      <td>Don't break up with him or call the cops.  If ...</td>\n",
       "      <td>It'll be dismissed: https://en.wikipedia.org/w...</td>\n",
       "      <td>Where is there a site that still works where y...</td>\n",
       "      <td>Because this statement of his is true. It isn'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>she will come your home open her legs with  an...</td>\n",
       "      <td>No Advertising: Spam, referral links, unsolici...</td>\n",
       "      <td>sex</td>\n",
       "      <td>Selling Tyrande codes for 3‚Ç¨ to paypal. PM. \\n...</td>\n",
       "      <td>tight pussy watch for your cock get her at thi...</td>\n",
       "      <td>NSFW(obviously) http://spankbang.com/iy3u/vide...</td>\n",
       "      <td>Good News ::Download WhatsApp 2.16.230 APK for...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>code free tyrande ---&gt;&gt;&gt; [Imgur](http://i.imgu...</td>\n",
       "      <td>No Advertising: Spam, referral links, unsolici...</td>\n",
       "      <td>hearthstone</td>\n",
       "      <td>wow!! amazing reminds me of the old days.Well...</td>\n",
       "      <td>seek for lady for sex in around http://p77.pl/...</td>\n",
       "      <td>must be watch movie https://sites.google.com/s...</td>\n",
       "      <td>We're streaming Pokemon Veitnamese Crystal RIG...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024</th>\n",
       "      <td>2024</td>\n",
       "      <td>Please edit your post so it is readable. These...</td>\n",
       "      <td>No legal advice: Do not offer or request legal...</td>\n",
       "      <td>relationships</td>\n",
       "      <td>I'm not ok with this in anyway, and think you ...</td>\n",
       "      <td>See a lawyer under the guise that you want thi...</td>\n",
       "      <td>This is just untrue.  OP is 13, not an adult -...</td>\n",
       "      <td>Why should I care about all the bicyclists I i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025</th>\n",
       "      <td>2025</td>\n",
       "      <td>Yes, and in a right to work state they can eve...</td>\n",
       "      <td>No legal advice: Do not offer or request legal...</td>\n",
       "      <td>legaladvice</td>\n",
       "      <td>Move as much of your assets as you can offshor...</td>\n",
       "      <td>We have great consumer protection laws. There'...</td>\n",
       "      <td>LPT piratebay, transmission, vpn. Get the musi...</td>\n",
       "      <td>It's not so much that I killed them, it's that...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026</th>\n",
       "      <td>2026</td>\n",
       "      <td>**HD** Streams: |ENG **HD**[ Watch here..PC &amp; ...</td>\n",
       "      <td>No Advertising: Spam, referral links, unsolici...</td>\n",
       "      <td>soccerstreams</td>\n",
       "      <td>stitopdisca1987.tumblr.com - sex Take girl for...</td>\n",
       "      <td>this girl get sex going to  to old http://mrk....</td>\n",
       "      <td>NO ADS | NO ADS | NO ADS\\n\\nWe show all SOCCER...</td>\n",
       "      <td>[So great! Thanks for sharing.](http://www.che...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2027</th>\n",
       "      <td>2027</td>\n",
       "      <td>No. Not when doing so obviously presents a saf...</td>\n",
       "      <td>No legal advice: Do not offer or request legal...</td>\n",
       "      <td>politics</td>\n",
       "      <td>SHE ISNT A BIRTHING CHAMBER BUT EQUALLY THE BA...</td>\n",
       "      <td>Jail? What are you, ten years old? If they pro...</td>\n",
       "      <td>Who cares about that when I can keep raping in...</td>\n",
       "      <td>send me a private message; I may be able to he...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2028</th>\n",
       "      <td>2028</td>\n",
       "      <td>&gt; CA is an at fault state so they will not be ...</td>\n",
       "      <td>No legal advice: Do not offer or request legal...</td>\n",
       "      <td>legaladvice</td>\n",
       "      <td>[Yes, it is. In the USA, at least](https://www...</td>\n",
       "      <td>Never pay a civil demand. \\n\\nIt's a bluff and...</td>\n",
       "      <td>Where is there a site that still works where y...</td>\n",
       "      <td>Steal a car from an elderly person who won't n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2029 rows √ó 9 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-27edc956-803d-43bc-9c63-67487054c243')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-27edc956-803d-43bc-9c63-67487054c243 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-27edc956-803d-43bc-9c63-67487054c243');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-833b6d0b-9a08-4c62-934f-6480ff00f807\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-833b6d0b-9a08-4c62-934f-6480ff00f807')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-833b6d0b-9a08-4c62-934f-6480ff00f807 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "  <div id=\"id_77f4c51a-5153-4d3d-9744-e54ddb50e07d\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_77f4c51a-5153-4d3d-9744-e54ddb50e07d button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('df');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "      row_id                                               body  \\\n",
       "0          0  Banks don't want you to know this! Click here ...   \n",
       "1          1  SD Stream [ ENG Link 1] (http://www.sportsstre...   \n",
       "2          2  Lol. Try appealing the ban and say you won't d...   \n",
       "3          3  she will come your home open her legs with  an...   \n",
       "4          4  code free tyrande --->>> [Imgur](http://i.imgu...   \n",
       "...      ...                                                ...   \n",
       "2024    2024  Please edit your post so it is readable. These...   \n",
       "2025    2025  Yes, and in a right to work state they can eve...   \n",
       "2026    2026  **HD** Streams: |ENG **HD**[ Watch here..PC & ...   \n",
       "2027    2027  No. Not when doing so obviously presents a saf...   \n",
       "2028    2028  > CA is an at fault state so they will not be ...   \n",
       "\n",
       "                                                   rule      subreddit  \\\n",
       "0     No Advertising: Spam, referral links, unsolici...     Futurology   \n",
       "1     No Advertising: Spam, referral links, unsolici...  soccerstreams   \n",
       "2     No legal advice: Do not offer or request legal...   pcmasterrace   \n",
       "3     No Advertising: Spam, referral links, unsolici...            sex   \n",
       "4     No Advertising: Spam, referral links, unsolici...    hearthstone   \n",
       "...                                                 ...            ...   \n",
       "2024  No legal advice: Do not offer or request legal...  relationships   \n",
       "2025  No legal advice: Do not offer or request legal...    legaladvice   \n",
       "2026  No Advertising: Spam, referral links, unsolici...  soccerstreams   \n",
       "2027  No legal advice: Do not offer or request legal...       politics   \n",
       "2028  No legal advice: Do not offer or request legal...    legaladvice   \n",
       "\n",
       "                                     positive_example_1  \\\n",
       "0     If you could tell your younger self something ...   \n",
       "1     [I wanna kiss you all over! Stunning!](http://...   \n",
       "2     Don't break up with him or call the cops.  If ...   \n",
       "3     Selling Tyrande codes for 3‚Ç¨ to paypal. PM. \\n...   \n",
       "4      wow!! amazing reminds me of the old days.Well...   \n",
       "...                                                 ...   \n",
       "2024  I'm not ok with this in anyway, and think you ...   \n",
       "2025  Move as much of your assets as you can offshor...   \n",
       "2026  stitopdisca1987.tumblr.com - sex Take girl for...   \n",
       "2027  SHE ISNT A BIRTHING CHAMBER BUT EQUALLY THE BA...   \n",
       "2028  [Yes, it is. In the USA, at least](https://www...   \n",
       "\n",
       "                                     positive_example_2  \\\n",
       "0     hunt for lady for jack off in neighbourhood ht...   \n",
       "1     LOLGA.COM is One of the First Professional Onl...   \n",
       "2     It'll be dismissed: https://en.wikipedia.org/w...   \n",
       "3     tight pussy watch for your cock get her at thi...   \n",
       "4     seek for lady for sex in around http://p77.pl/...   \n",
       "...                                                 ...   \n",
       "2024  See a lawyer under the guise that you want thi...   \n",
       "2025  We have great consumer protection laws. There'...   \n",
       "2026  this girl get sex going to  to old http://mrk....   \n",
       "2027  Jail? What are you, ten years old? If they pro...   \n",
       "2028  Never pay a civil demand. \\n\\nIt's a bluff and...   \n",
       "\n",
       "                                     negative_example_1  \\\n",
       "0     Watch Golden Globe Awards 2017 Live Online in ...   \n",
       "1     #Rapper \\nüö®Straight Outta Cross Keys SC üö®YouTu...   \n",
       "2     Where is there a site that still works where y...   \n",
       "3     NSFW(obviously) http://spankbang.com/iy3u/vide...   \n",
       "4     must be watch movie https://sites.google.com/s...   \n",
       "...                                                 ...   \n",
       "2024  This is just untrue.  OP is 13, not an adult -...   \n",
       "2025  LPT piratebay, transmission, vpn. Get the musi...   \n",
       "2026  NO ADS | NO ADS | NO ADS\\n\\nWe show all SOCCER...   \n",
       "2027  Who cares about that when I can keep raping in...   \n",
       "2028  Where is there a site that still works where y...   \n",
       "\n",
       "                                     negative_example_2  rule_violation  \n",
       "0     DOUBLE CEE x BANDS EPPS - \"BIRDS\"\\n\\nDOWNLOAD/...               0  \n",
       "1     [15 Amazing Hidden Features Of Google Search Y...               0  \n",
       "2     Because this statement of his is true. It isn'...               1  \n",
       "3     Good News ::Download WhatsApp 2.16.230 APK for...               1  \n",
       "4     We're streaming Pokemon Veitnamese Crystal RIG...               1  \n",
       "...                                                 ...             ...  \n",
       "2024  Why should I care about all the bicyclists I i...               1  \n",
       "2025  It's not so much that I killed them, it's that...               0  \n",
       "2026  [So great! Thanks for sharing.](http://www.che...               1  \n",
       "2027  send me a private message; I may be able to he...               1  \n",
       "2028  Steal a car from an elderly person who won't n...               1  \n",
       "\n",
       "[2029 rows x 9 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_folder = base_folder/'datasets'\n",
    "df = pd.read_csv(data_folder/'train.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bJnCcArQJ0Vd",
   "metadata": {
    "id": "bJnCcArQJ0Vd"
   },
   "source": [
    "# <font color = 'indianred'> **3. Accessing and Manuplating Splits**</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "uvCUBOG-MDce",
   "metadata": {},
   "outputs": [],
   "source": [
    "jigsaw_dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "oF7x5JYiqZGL",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine comment body, rule, and subreddit into a single contextual text field\n",
    "df['text'] = (\n",
    "    \"Comment: \" + df['body'].fillna('') +\n",
    "    \" | Rule: \" + df['rule'].fillna('') +\n",
    "    \" | Subreddit: \" + df['subreddit'].fillna('')\n",
    ")\n",
    "\n",
    "# Keep only the necessary columns\n",
    "selected_columns = {\n",
    "    \"text\": df[\"text\"],\n",
    "    \"tag\": df[\"rule_violation\"]\n",
    "}\n",
    "\n",
    "# Create new dataset as before\n",
    "jigsaw_selected_columns = Dataset.from_dict(selected_columns)\n",
    "jigsaw_selected_columns.set_format(type='pandas')\n",
    "\n",
    "df = jigsaw_selected_columns[:]\n",
    "df['label'] = df['tag'].astype(int)\n",
    "df['label_text'] = df['label'].map({0: 'complies', 1: 'violates'})\n",
    "jigsaw_selected_column_final = Dataset.from_pandas(df, preserve_index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "F4Lpc6ItMyUi",
   "metadata": {
    "id": "F4Lpc6ItMyUi"
   },
   "source": [
    "<font color = 'indianred'>*Create futher subdivions of the splits*</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a8YTYKAMhaV",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the test set into test and validation sets\n",
    "test_val_splits = jigsaw_selected_column_final.train_test_split(test_size=0.2, seed=42)\n",
    "train_split= test_val_splits['train']\n",
    "test_val_splits = test_val_splits['test'].train_test_split(test_size=0.5, seed=42,)\n",
    "val_split = test_val_splits['train']\n",
    "test_split = test_val_splits['test']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CY6NEjV6z7-i",
   "metadata": {
    "id": "CY6NEjV6z7-i"
   },
   "source": [
    "<font color = 'indianred'>*small subset for initial experimenttaion*</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "hXBQt1306m4C",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_subset = DatasetDict({\"train\": train_split, \"valid\": val_split, \"test\": test_split})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "VgNj2At3kRSs",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'tag', 'label', 'label_text'],\n",
       "        num_rows: 1623\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['text', 'tag', 'label', 'label_text'],\n",
       "        num_rows: 203\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'tag', 'label', 'label_text'],\n",
       "        num_rows: 203\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b02690-50f7-49bf-aab4-85dbbb21d182",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T11:21:48.647438Z",
     "iopub.status.busy": "2022-12-20T11:21:48.646659Z",
     "iopub.status.idle": "2022-12-20T11:21:48.690232Z",
     "shell.execute_reply": "2022-12-20T11:21:48.689729Z",
     "shell.execute_reply.started": "2022-12-20T11:21:48.647414Z"
    },
    "id": "c7b02690-50f7-49bf-aab4-85dbbb21d182",
    "tags": []
   },
   "source": [
    "# <font color = 'indianred'>**4. Load pre-trained Tokenizer**</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "pPGuUj3bZUDU",
   "metadata": {},
   "outputs": [],
   "source": [
    "def free_gpu_memory():\n",
    "    \"\"\"\n",
    "    Frees up GPU memory after CUDA out-of-memory error in Colab.\n",
    "\n",
    "    This function performs the following steps:\n",
    "    1. Deletes all PyTorch objects to clear references.\n",
    "    2. Calls garbage collection to remove unreferenced objects from memory.\n",
    "    3. Uses torch.cuda.empty_cache() to release cached GPU memory.\n",
    "    4. Waits for a moment to ensure memory is fully released.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Delete all torch tensors to free up memory\n",
    "        for obj in list(locals().values()):\n",
    "            if torch.is_tensor(obj):\n",
    "                del obj\n",
    "\n",
    "        # Collect garbage to release any remaining unused memory\n",
    "        gc.collect()\n",
    "\n",
    "        # Empty the CUDA cache to release GPU memory\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        # Adding a small delay to allow memory to be fully released\n",
    "        time.sleep(2)\n",
    "\n",
    "        print(\"GPU memory has been freed.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error while freeing GPU memory: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "JOQFmHUXlzkw",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory has been freed.\n"
     ]
    }
   ],
   "source": [
    "free_gpu_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "hzUiqZR6hI4o",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"google/gemma-2-2b\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e4vsyN5kbyPQ",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'<eos>'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "VlPaFtAQ-tnR",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'<pad>'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "Tu9xXCUYgM26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'left'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.padding_side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5dda69a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.chat_template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4ce3b9-904f-42bd-9c3f-163328f47051",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-20T11:22:33.679936Z",
     "iopub.status.busy": "2022-12-20T11:22:33.679764Z",
     "iopub.status.idle": "2022-12-20T11:22:33.723366Z",
     "shell.execute_reply": "2022-12-20T11:22:33.722847Z",
     "shell.execute_reply.started": "2022-12-20T11:22:33.679918Z"
    },
    "id": "2b4ce3b9-904f-42bd-9c3f-163328f47051"
   },
   "source": [
    "#<font color = 'indianred'> **5. Create Completion Dataset**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "PFRvJTd7MzwQ",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_prompt_completion(example):\n",
    "    prompt = (\n",
    "        \"Does the following Reddit comment violate the subreddit rules? \"\n",
    "        \"Answer 'complies' or 'violates'.\\n\\n\"\n",
    "        f\"Comment: {example['text'].strip()}\\n\"\n",
    "        \"Answer:\"\n",
    "    )\n",
    "    completion = f\" {example['label_text']}\"   # <-- one word target\n",
    "    return {\"prompt\": prompt, \"completion\": completion}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "NXw2qlGKJvuA",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42906732ade94fd4831181ba001e8c80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1623 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bf6fd202e1b44a395464c1385a91e3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e923c52326224ad1af05b48c130651ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_subset_completition = data_subset.map(format_prompt_completion, remove_columns=[\"text\", \"label\", \"label_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "26MsfYeILJpO",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tag', 'prompt', 'completion'],\n",
       "        num_rows: 1623\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['tag', 'prompt', 'completion'],\n",
       "        num_rows: 203\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['tag', 'prompt', 'completion'],\n",
       "        num_rows: 203\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_subset_completition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "52VW86pfJ3Pr",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tag': 1,\n",
       " 'prompt': \"Does the following Reddit comment violate the subreddit rules? Answer 'complies' or 'violates'.\\n\\nComment: Comment: unethical but... make a SS# but state name and address and all perfectly.  If the IRS asks, just say that's the number you got, let the IRS sort if out for you. | Rule: No legal advice: Do not offer or request legal advice. | Subreddit: personalfinance\\nAnswer:\",\n",
       " 'completion': ' violates'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_subset_completition['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mx3Waetkm6xm",
   "metadata": {
    "id": "mx3Waetkm6xm"
   },
   "source": [
    "##  <font color = 'indianred'> **5.1 Filter Longer sequences**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "qNW-3CK7MfBZ",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fbe8fa5ad57487189022677066bbe2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1623 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ccc3fee880d48b1873488e0e94a68d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7ddd126d7df4666a8c47053280bf370",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f81a7aa17254a8084d01364c7a993ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/1623 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a3bf7c07b0c4d85b39522d4615318af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f59a865e83e49618eb883f84e2f585e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_subset_completition = data_subset_completition.map(\n",
    "    lambda example: {'keep': len(tokenizer.encode(example['prompt'])) <= 1024}\n",
    ")\n",
    "\n",
    "# Then filter\n",
    "data_subset_completition = data_subset_completition.filter(lambda x: x['keep'])\n",
    "data_subset_completition = data_subset_completition.remove_columns(['keep'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "Dwt6deImM2kJ",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tag', 'prompt', 'completion'],\n",
       "        num_rows: 1623\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['tag', 'prompt', 'completion'],\n",
       "        num_rows: 203\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['tag', 'prompt', 'completion'],\n",
       "        num_rows: 203\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_subset_completition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bxYYwhUfM5__",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tag': 1,\n",
       " 'prompt': \"Does the following Reddit comment violate the subreddit rules? Answer 'complies' or 'violates'.\\n\\nComment: Comment: unethical but... make a SS# but state name and address and all perfectly.  If the IRS asks, just say that's the number you got, let the IRS sort if out for you. | Rule: No legal advice: Do not offer or request legal advice. | Subreddit: personalfinance\\nAnswer:\",\n",
       " 'completion': ' violates'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_subset_completition['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TwUqYaXxC7qv",
   "metadata": {
    "id": "TwUqYaXxC7qv"
   },
   "source": [
    "##  <font color = 'indianred'> **5.2 Push Dataset to Hub**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "zLD9aYWbLfHD",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b0560c0f8984c2787b11aa9f9512a93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ? shards/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f25b9deed0a54a298995a584fd7b2568",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "500fbc7cc317450aa9a463c2038c3ed3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aa00c7ba504490eb6f482d414be7c4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload               : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0e246a0c2e543cdb9cf1f2cb59f1a21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "                              : 100%|##########|  245kB /  245kB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9816edbb47b8490895019e89fc4a4888",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ? shards/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8a30df83c2546fba89b16ceda4aeab8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d1c6487b1ad40c5b923950bcf788fdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57c149893dca4d83a8824c2aacadacac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload               : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c31301183c24eecafc3c157c8483fc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "                              : 100%|##########| 32.6kB / 32.6kB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "283fc28da43a42239373dee9141bc85c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ? shards/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5892b783da4b4f999a861d0a978cceda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93efb2a065d6454ea5d0108e430de92c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5585967cf4594522a7ee78917872f8f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload               : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f97157d7a66147f38e4351b3ac43f15b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "                              : 100%|##########| 33.0kB / 33.0kB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0d4f958f41a4ecbb21d7fdff8c3e529",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/538 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n",
      "WARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/Ron00769/jigsaw_binary_base_language_head/commit/c8556bebe22db224d299de66ba72408a34113503', commit_message='Upload dataset', commit_description='', oid='c8556bebe22db224d299de66ba72408a34113503', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/Ron00769/jigsaw_binary_base_language_head', endpoint='https://huggingface.co', repo_type='dataset', repo_id='Ron00769/jigsaw_binary_base_language_head'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_subset_completition.push_to_hub(\n",
    "    \"Ron00769/jigsaw_binary_base_language_head\",\n",
    "    private=False  # Set to True if you want it private\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "Uc70zod4x-X5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filtered = data_subset_completition['train']\n",
    "valid_filtered = data_subset_completition['valid']\n",
    "test_filtered = data_subset_completition['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "O7-5sm2uBTN_",
   "metadata": {
    "id": "O7-5sm2uBTN_"
   },
   "source": [
    "#  <font color = 'indianred'> **6. Model Training**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2a39fc-6d87-43ca-8a6e-7129bd8214f1",
   "metadata": {
    "id": "cc2a39fc-6d87-43ca-8a6e-7129bd8214f1"
   },
   "source": [
    "##  <font color = 'indianred'> **6.1 Download pre-trained model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "Uh43-6J8LWlS",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_appropriate_dtype():\n",
    "    if torch.cuda.is_available() and torch.cuda.get_device_capability(0) >= (8, 0):\n",
    "        return torch.bfloat16\n",
    "    return torch.float16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "CBvrKgAeLZJV",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.bfloat16"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_data_type = get_appropriate_dtype()\n",
    "torch_data_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "g46jiz0vLSGk",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "  load_in_4bit=True,\n",
    "  bnb_4bit_quant_type=\"nf4\",\n",
    "  bnb_4bit_use_double_quant=True,\n",
    "  bnb_4bit_compute_dtype=torch_data_type,\n",
    "  bnb_4bit_quant_storage=torch_data_type,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "58babf85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "531b86f0c057465a8ab83a74f5b60c50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/818 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af8e04e50e9d4c3ea4a2444945624265",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/24.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9bd999754c649c6938ddb7dcbb01178",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3126ec90df6482bbea63d1f6e47247d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff140c10a8a742d79f2335e4b66521c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f8b86e4f1134cf8bd58b6eca1909abb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/481M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1971d1a9b0cc42968b2f0eb5fb981c20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8055ada10f7a4b109335d4de73f5db06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/168 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(checkpoint,\n",
    "                                             quantization_config=bnb_config,\n",
    "                                             torch_dtype=torch_data_type,\n",
    "                                             trust_remote_code=True,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GS6SSVBUpFz1",
   "metadata": {
    "id": "GS6SSVBUpFz1"
   },
   "source": [
    "##  <font color = 'indianred'> **6.2 PEFT Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "DTgloiC4pps7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gemma2ForCausalLM(\n",
       "  (model): Gemma2Model(\n",
       "    (embed_tokens): Embedding(256000, 2304, padding_idx=0)\n",
       "    (layers): ModuleList(\n",
       "      (0-25): 26 x Gemma2DecoderLayer(\n",
       "        (self_attn): Gemma2Attention(\n",
       "          (q_proj): Linear4bit(in_features=2304, out_features=2048, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=2304, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=2304, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=2048, out_features=2304, bias=False)\n",
       "        )\n",
       "        (mlp): Gemma2MLP(\n",
       "          (gate_proj): Linear4bit(in_features=2304, out_features=9216, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=2304, out_features=9216, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=9216, out_features=2304, bias=False)\n",
       "          (act_fn): GELUTanh()\n",
       "        )\n",
       "        (input_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
       "        (post_attention_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
       "        (pre_feedforward_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
       "        (post_feedforward_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
       "    (rotary_emb): Gemma2RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2304, out_features=256000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "eq60NtZWszfC",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_linear_layers(model):\n",
    "    \"\"\"\n",
    "    Extracts the unique names of Linear layers from a model.\n",
    "\n",
    "    Args:\n",
    "    model (nn.Module): The model from which to extract Linear layer names.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of unique names of Linear layers.\n",
    "    \"\"\"\n",
    "    # Convert the model's modules to string\n",
    "    model_modules = str(model.modules)\n",
    "    # Pattern to extract names of Linear layers\n",
    "    pattern = r'\\((\\w+)\\): Linear'\n",
    "    # Find all occurrences of the pattern\n",
    "    linear_layer_names = re.findall(pattern, model_modules)\n",
    "    print(linear_layer_names)\n",
    "    # Get unique names using a set, then convert back to list\n",
    "    target_modules = list(set(linear_layer_names))\n",
    "    return target_modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "WOiU0qHIpaL-",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj', 'lm_head']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['k_proj',\n",
       " 'down_proj',\n",
       " 'lm_head',\n",
       " 'q_proj',\n",
       " 'o_proj',\n",
       " 'up_proj',\n",
       " 'v_proj',\n",
       " 'gate_proj']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_linear_layers(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "Ixm-x8g5DLh-",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "<TaskType.CAUSAL_LM: 'CAUSAL_LM'>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TaskType.CAUSAL_LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "PF49fLAjphS-",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    r=128,\n",
    "    lora_alpha=256,\n",
    "    lora_dropout=0.01,\n",
    "    target_modules = ['v_proj',  'q_proj',  'up_proj', 'o_proj', 'down_proj', 'gate_proj','k_proj'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Jwwp80UgmLjr",
   "metadata": {
    "id": "Jwwp80UgmLjr"
   },
   "source": [
    "## <font color = 'indianred'> **6.3 Training Arguments**</font>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "hIXDbzK8O4x9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory where model checkpoints will be saved\n",
    "\n",
    "model_folder = base_folder/'models/jigsaw/decoder_with_language_head'\n",
    "# Create the directory if it doesn't exist\n",
    "model_folder.mkdir(exist_ok=True, parents=True)\n",
    "run_name= 'jigsaw_exp_lmh_gemma_base'\n",
    "\n",
    "use_fp16 = torch_data_type == torch.float16\n",
    "use_bf16 = torch_data_type == torch.bfloat16\n",
    "\n",
    "# Configure training parameters\n",
    "training_args = SFTConfig(\n",
    "    seed = 42,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_length = 1024,\n",
    "    packing = False,\n",
    "    remove_unused_columns=False,\n",
    "    completion_only_loss=True,\n",
    "\n",
    "    # Training-specific configurations\n",
    "    num_train_epochs=2,  # Total number of training epochs\n",
    "    per_device_train_batch_size=8, # Number of samples per training batch for each device\n",
    "    per_device_eval_batch_size=8,  # Number of samples per evaluation batch for each device\n",
    "    gradient_accumulation_steps=2,\n",
    "    gradient_checkpointing=True,\n",
    "    gradient_checkpointing_kwargs={\"use_reentrant\":False},\n",
    "    torch_empty_cache_steps=20,\n",
    "    weight_decay=0.0,  # Apply L2 regularization to prevent overfitting\n",
    "    learning_rate=1e-5,  # Step size for the optimizer during training\n",
    "    optim='adamw_torch',  # Optimizer,\n",
    "\n",
    "    # Checkpoint saving and model evaluation settings\n",
    "    output_dir=str(model_folder),  # Directory to save model checkpoints\n",
    "    eval_strategy='steps',  # Evaluate model at specified step intervals\n",
    "    eval_steps=20,  # Perform evaluation every 10 training steps\n",
    "    save_strategy=\"steps\",  # Save model checkpoint at specified step intervals\n",
    "    save_steps=20,  # Save a model checkpoint every 10 training steps\n",
    "    load_best_model_at_end=True,  # Reload the best model at the end of training\n",
    "    save_total_limit=2,  # Retain only the best and the most recent model checkpoints\n",
    "    # Use 'accuracy' as the metric to determine the best model\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,  # A model is 'better' if its accuracy is higher\n",
    "\n",
    "\n",
    "    # Experiment logging configurations (commented out in this example)\n",
    "    logging_strategy='steps',\n",
    "    logging_steps=20,\n",
    "    report_to='wandb',  # Log metrics and results to Weights & Biases platform\n",
    "    run_name= run_name,  # Experiment name for Weights & Biases\n",
    "\n",
    "    # Precision settings determined based on GPU capability\n",
    "    fp16=use_fp16 ,  # Set True if torch_data_type is torch.float16\n",
    "    bf16=use_bf16,  # Set True if torch_data_type is torch.bfloat16\n",
    "    tf32=False,  # Disable tf32 unless you want to use Ampere specific optimization\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "exUBN-oC51xA",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gemma2Config {\n",
       "  \"architectures\": [\n",
       "    \"Gemma2ForCausalLM\"\n",
       "  ],\n",
       "  \"attention_bias\": false,\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"attn_logit_softcapping\": 50.0,\n",
       "  \"bos_token_id\": 2,\n",
       "  \"cache_implementation\": \"hybrid\",\n",
       "  \"dtype\": \"bfloat16\",\n",
       "  \"eos_token_id\": 1,\n",
       "  \"final_logit_softcapping\": 30.0,\n",
       "  \"head_dim\": 256,\n",
       "  \"hidden_act\": \"gelu_pytorch_tanh\",\n",
       "  \"hidden_activation\": \"gelu_pytorch_tanh\",\n",
       "  \"hidden_size\": 2304,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 9216,\n",
       "  \"layer_types\": [\n",
       "    \"sliding_attention\",\n",
       "    \"full_attention\",\n",
       "    \"sliding_attention\",\n",
       "    \"full_attention\",\n",
       "    \"sliding_attention\",\n",
       "    \"full_attention\",\n",
       "    \"sliding_attention\",\n",
       "    \"full_attention\",\n",
       "    \"sliding_attention\",\n",
       "    \"full_attention\",\n",
       "    \"sliding_attention\",\n",
       "    \"full_attention\",\n",
       "    \"sliding_attention\",\n",
       "    \"full_attention\",\n",
       "    \"sliding_attention\",\n",
       "    \"full_attention\",\n",
       "    \"sliding_attention\",\n",
       "    \"full_attention\",\n",
       "    \"sliding_attention\",\n",
       "    \"full_attention\",\n",
       "    \"sliding_attention\",\n",
       "    \"full_attention\",\n",
       "    \"sliding_attention\",\n",
       "    \"full_attention\",\n",
       "    \"sliding_attention\",\n",
       "    \"full_attention\"\n",
       "  ],\n",
       "  \"max_position_embeddings\": 8192,\n",
       "  \"model_type\": \"gemma2\",\n",
       "  \"num_attention_heads\": 8,\n",
       "  \"num_hidden_layers\": 26,\n",
       "  \"num_key_value_heads\": 4,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"quantization_config\": {\n",
       "    \"_load_in_4bit\": true,\n",
       "    \"_load_in_8bit\": false,\n",
       "    \"bnb_4bit_compute_dtype\": \"bfloat16\",\n",
       "    \"bnb_4bit_quant_storage\": \"bfloat16\",\n",
       "    \"bnb_4bit_quant_type\": \"nf4\",\n",
       "    \"bnb_4bit_use_double_quant\": true,\n",
       "    \"llm_int8_enable_fp32_cpu_offload\": false,\n",
       "    \"llm_int8_has_fp16_weight\": false,\n",
       "    \"llm_int8_skip_modules\": null,\n",
       "    \"llm_int8_threshold\": 6.0,\n",
       "    \"load_in_4bit\": true,\n",
       "    \"load_in_8bit\": false,\n",
       "    \"quant_method\": \"bitsandbytes\"\n",
       "  },\n",
       "  \"query_pre_attn_scalar\": 256,\n",
       "  \"rms_norm_eps\": 1e-06,\n",
       "  \"rope_theta\": 10000.0,\n",
       "  \"sliding_window\": 4096,\n",
       "  \"transformers_version\": \"4.57.1\",\n",
       "  \"use_cache\": false,\n",
       "  \"vocab_size\": 256000\n",
       "}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If gradient checkpointing is enabled, configure relevant settings\n",
    "if training_args.gradient_checkpointing:\n",
    "    model.config.use_cache = False  # Disable caching for compatibility\n",
    "model.config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "J_hMcxgrFNyT",
   "metadata": {
    "id": "J_hMcxgrFNyT"
   },
   "source": [
    "##  <font color = 'indianred'> **6.4 Initialize Trainer**</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "iEtX_DvoAoTn",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8592c378231c4de3803bf4575b1fa246",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding EOS to train dataset:   0%|          | 0/1623 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d710317e490a4e37b88385fabc1fe8a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/1623 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba380dbf4ebc4d34b6661ac3e133726a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating train dataset:   0%|          | 0/1623 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "802072c0360b421cb05c16ec1cc60cce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding EOS to eval dataset:   0%|          | 0/203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4384b549966a4cb2bf1fd2252dcf8e04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing eval dataset:   0%|          | 0/203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e37c865dc5c4134b527ae685eb6bcea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating eval dataset:   0%|          | 0/203 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_filtered,\n",
    "    eval_dataset=valid_filtered,\n",
    "    peft_config=peft_config,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0xXoDiyoWaq9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = trainer.get_train_dataloader()\n",
    "batch = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8UsTOWFMGmCJ",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([    2, 11227,   573,  2412, 30775], device='cuda:0')\n",
      "<bos>Does the following Reddit\n",
      "tensor([-100, -100, -100, -100, -100], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(batch['input_ids'][0][0:5])\n",
    "print(tokenizer.decode(batch['input_ids'][0][0:5]))\n",
    "print(batch['labels'][0][0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bUYol-XpIDji",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    2, 11227,   573,  ...,     0,     0,     0],\n",
       "         [    2, 11227,   573,  ...,     0,     0,     0],\n",
       "         [    2, 11227,   573,  ...,     0,     0,     0],\n",
       "         ...,\n",
       "         [    2, 11227,   573,  ...,     0,     0,     0],\n",
       "         [    2, 11227,   573,  ...,     0,     0,     0],\n",
       "         [    2, 11227,   573,  ...,     0,     0,     0]], device='cuda:0'),\n",
       " 'labels': tensor([[-100, -100, -100,  ..., -100, -100, -100],\n",
       "         [-100, -100, -100,  ..., -100, -100, -100],\n",
       "         [-100, -100, -100,  ..., -100, -100, -100],\n",
       "         ...,\n",
       "         [-100, -100, -100,  ..., -100, -100, -100],\n",
       "         [-100, -100, -100,  ..., -100, -100, -100],\n",
       "         [-100, -100, -100,  ..., -100, -100, -100]], device='cuda:0'),\n",
       " 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "gsH1tgruIYgm",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187\n",
      "187\n"
     ]
    }
   ],
   "source": [
    "print(len(batch['input_ids'][0]))\n",
    "print(len(batch['labels'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0YO1jqdVIv4n",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([    2, 11227,   573,  2412, 30775], device='cuda:0')\n",
      "<bos>Does the following Reddit\n",
      "tensor([-100, -100, -100, -100, -100], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(batch['input_ids'][0][0:5])\n",
    "print(tokenizer.decode(batch['input_ids'][0][0:5]))\n",
    "print(batch['labels'][0][0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "KihOR7tTLBCZ",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INPUTS\n",
      "--------------------------------------------------------------------------------\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "\n",
      "LABELS\n",
      "--------------------------------------------------------------------------------\n",
      "tensor([-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100], device='cuda:0')\n",
      "\n",
      "Tokens\n",
      "--------------------------------------------------------------------------------\n",
      "<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nINPUTS\")\n",
    "print(f\"{'-'*80}\")\n",
    "print(batch['input_ids'][0][99:114])\n",
    "print(f\"\\nLABELS\")\n",
    "print(f\"{'-'*80}\")\n",
    "print(batch['labels'][0][99:114])\n",
    "print(f\"\\nTokens\")\n",
    "print(f\"{'-'*80}\")\n",
    "print(tokenizer.decode(batch['input_ids'][0][99:114]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8S4jcqLExvKd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_loss_masking(tokenizer, trainer, num_samples=3):\n",
    "    \"\"\"\n",
    "    Verify which tokens contribute to loss (labels != -100)\n",
    "    for a few samples from the training dataloader.\n",
    "    \"\"\"\n",
    "    dataloader = trainer.get_train_dataloader()\n",
    "    batch = next(iter(dataloader))\n",
    "\n",
    "    for i in range(min(num_samples, len(batch[\"input_ids\"]))):\n",
    "        input_ids = batch[\"input_ids\"][i]\n",
    "        labels = batch[\"labels\"][i]\n",
    "\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Sample {i+1}\")\n",
    "        print(f\"{'='*80}\")\n",
    "\n",
    "        # Decode full sequence for reference\n",
    "        full_text = tokenizer.decode(input_ids, skip_special_tokens=False)\n",
    "        pprint(f\"\\nFull text:\\n{full_text}\")\n",
    "\n",
    "        # Identify tokens used for loss\n",
    "        loss_token_indices = (labels != -100).nonzero(as_tuple=True)[0]\n",
    "\n",
    "        if len(loss_token_indices) == 0:\n",
    "            print(\"All tokens masked ‚Äî no loss will be calculated.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nTokens contributing to loss ({len(loss_token_indices)} total):\")\n",
    "        print(f\"{'-'*80}\")\n",
    "        print(f\"{'Index':<8} {'Token ID':<10} {'Token Text'}\")\n",
    "        print(f\"{'-'*80}\")\n",
    "\n",
    "        for idx in loss_token_indices.tolist():\n",
    "            token_id = input_ids[idx].item()\n",
    "            token_text = tokenizer.decode([token_id], skip_special_tokens=False)\n",
    "            print(f\"{idx:<8} {token_id:<10} {repr(token_text)}\")\n",
    "\n",
    "        print(f\"{'-'*80}\")\n",
    "        print(f\"Percentage of tokens used for loss: {len(loss_token_indices)/len(labels)*100:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "keJ8x1NbySgx",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Sample 1\n",
      "================================================================================\n",
      "('\\n'\n",
      " 'Full text:\\n'\n",
      " '<bos>Does the following Reddit comment violate the subreddit rules? Answer '\n",
      " \"'complies' or 'violates'.\\n\"\n",
      " '\\n'\n",
      " 'Comment: Comment: naughty holes wait you there http://by.ix-cafe.com/4j3pu | '\n",
      " 'Rule: No Advertising: Spam, referral links, unsolicited advertising, and '\n",
      " 'promotional content are not allowed. | Subreddit: Showerthoughts\\n'\n",
      " 'Answer: '\n",
      " 'violates<eos><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>')\n",
      "\n",
      "Tokens contributing to loss (2 total):\n",
      "--------------------------------------------------------------------------------\n",
      "Index    Token ID   Token Text\n",
      "--------------------------------------------------------------------------------\n",
      "75       97650      ' violates'\n",
      "76       1          '<eos>'\n",
      "--------------------------------------------------------------------------------\n",
      "Percentage of tokens used for loss: 1.07%\n",
      "\n",
      "================================================================================\n",
      "Sample 2\n",
      "================================================================================\n",
      "('\\n'\n",
      " 'Full text:\\n'\n",
      " '<bos>Does the following Reddit comment violate the subreddit rules? Answer '\n",
      " \"'complies' or 'violates'.\\n\"\n",
      " '\\n'\n",
      " \"Comment: Comment: Here's my referral link, thanks and enjoy!: \"\n",
      " 'https://www.regions.referlive.com/newcustform/364X5F0XAAAB/14/0840084ZAHDWQ3N '\n",
      " '| Rule: No Advertising: Spam, referral links, unsolicited advertising, and '\n",
      " 'promotional content are not allowed. | Subreddit: churning\\n'\n",
      " 'Answer: '\n",
      " 'violates<eos><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>')\n",
      "\n",
      "Tokens contributing to loss (2 total):\n",
      "--------------------------------------------------------------------------------\n",
      "Index    Token ID   Token Text\n",
      "--------------------------------------------------------------------------------\n",
      "108      97650      ' violates'\n",
      "109      1          '<eos>'\n",
      "--------------------------------------------------------------------------------\n",
      "Percentage of tokens used for loss: 1.07%\n"
     ]
    }
   ],
   "source": [
    "# Call this after creating your trainer\n",
    "verify_loss_masking(tokenizer, trainer, num_samples=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "IGDxeCI38uqm",
   "metadata": {
    "id": "IGDxeCI38uqm"
   },
   "source": [
    "## <font color = 'indianred'> **6.5 Setup WandB**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "S8CaRySh81mi",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_PROJECT=jigsaw_language_head_2025\n"
     ]
    }
   ],
   "source": [
    "%env WANDB_PROJECT = jigsaw_language_head_2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ty027fT4DFGn",
   "metadata": {
    "id": "ty027fT4DFGn"
   },
   "source": [
    "##  <font color = 'indianred'> **6.6 Start Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "RVurPfZHvOKK",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20251103_014835-nzmr0oea</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ronchaudhuri29-the-university-of-texas-at-dallas/jigsaw_language_head_2025/runs/nzmr0oea' target=\"_blank\">jigsaw_exp_lmh_gemma_base</a></strong> to <a href='https://wandb.ai/ronchaudhuri29-the-university-of-texas-at-dallas/jigsaw_language_head_2025' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ronchaudhuri29-the-university-of-texas-at-dallas/jigsaw_language_head_2025' target=\"_blank\">https://wandb.ai/ronchaudhuri29-the-university-of-texas-at-dallas/jigsaw_language_head_2025</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ronchaudhuri29-the-university-of-texas-at-dallas/jigsaw_language_head_2025/runs/nzmr0oea' target=\"_blank\">https://wandb.ai/ronchaudhuri29-the-university-of-texas-at-dallas/jigsaw_language_head_2025/runs/nzmr0oea</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='204' max='204' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [204/204 06:31, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Entropy</th>\n",
       "      <th>Num Tokens</th>\n",
       "      <th>Mean Token Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.546900</td>\n",
       "      <td>0.445790</td>\n",
       "      <td>2.380119</td>\n",
       "      <td>32551.000000</td>\n",
       "      <td>0.750801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.350900</td>\n",
       "      <td>0.319272</td>\n",
       "      <td>2.440371</td>\n",
       "      <td>65156.000000</td>\n",
       "      <td>0.808494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.307600</td>\n",
       "      <td>0.312283</td>\n",
       "      <td>2.472125</td>\n",
       "      <td>98444.000000</td>\n",
       "      <td>0.834135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.281600</td>\n",
       "      <td>0.274867</td>\n",
       "      <td>2.455178</td>\n",
       "      <td>131103.000000</td>\n",
       "      <td>0.848558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.255600</td>\n",
       "      <td>0.274582</td>\n",
       "      <td>2.460648</td>\n",
       "      <td>164196.000000</td>\n",
       "      <td>0.850962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.220600</td>\n",
       "      <td>0.288750</td>\n",
       "      <td>2.463992</td>\n",
       "      <td>195997.000000</td>\n",
       "      <td>0.860577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.214800</td>\n",
       "      <td>0.272556</td>\n",
       "      <td>2.451506</td>\n",
       "      <td>229211.000000</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.191000</td>\n",
       "      <td>0.291300</td>\n",
       "      <td>2.419691</td>\n",
       "      <td>261922.000000</td>\n",
       "      <td>0.872596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.188200</td>\n",
       "      <td>0.290672</td>\n",
       "      <td>2.421956</td>\n",
       "      <td>293573.000000</td>\n",
       "      <td>0.867788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.199100</td>\n",
       "      <td>0.277554</td>\n",
       "      <td>2.431101</td>\n",
       "      <td>327473.000000</td>\n",
       "      <td>0.877404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    # Your code that may cause a CUDA out-of-memory error\n",
    "    # Example: trainer.train() or other GPU intensive operations\n",
    "    # lora_model.config.use_cache = False\n",
    "    trainer.train()\n",
    "except RuntimeError as e:\n",
    "    if 'CUDA out of memory' in str(e):\n",
    "        print(\"CUDA out of memory error detected. Freeing GPU memory.\")\n",
    "        free_gpu_memory()\n",
    "        # Optionally, you can retry the operation here after freeing up memory\n",
    "        # Example retry:\n",
    "        # trainer.train()\n",
    "    else:\n",
    "        raise e\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "r7GN6usfI-KW",
   "metadata": {
    "id": "r7GN6usfI-KW"
   },
   "source": [
    "##  <font color = 'indianred'> **6.7 Push best checkpoint to Hub**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "W0ZwbDiZz8Ol",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_checkpoint_step = trainer.state.best_model_checkpoint.split('-')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1HrLydYRz8-v",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'140'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_checkpoint_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "lRTl650Wyf4y",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content/drive/MyDrive/data/models/jigsaw/decoder_with_language_head/checkpoint-140'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = str(model_folder/f'checkpoint-{best_model_checkpoint_step}')\n",
    "checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e362a7fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "495d588752f641e78b2d7fba133b0b32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "583ce7cc0fd049268313cdf493cf3b9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload               : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e26201a35d3240afa90f8cc1505f8ab7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...kpoint-140/tokenizer.json:  97%|#########7| 33.5MB / 34.4MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "024c2c50a6ba4aa485c46800a90e2f0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...point-140/tokenizer.model: 100%|##########| 4.24MB / 4.24MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d83fbf52348e4b579e78bb67e6c5b6ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...eckpoint-140/optimizer.pt:   0%|          |  565kB / 1.33GB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38efea12bc4945aaa0fa9e67c6a850a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...adapter_model.safetensors:   0%|          | 43.0kB /  665MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c26f3c0cc6024d53ab8549f17172a746",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...eckpoint-140/scheduler.pt: 100%|##########| 1.47kB / 1.47kB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e8a36ba43604dc69aaf23b9d50e606e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...ckpoint-140/rng_state.pth:  77%|#######7  | 11.3kB / 14.6kB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3047e82642f4b5e9f26163b15e7988e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...int-140/training_args.bin:   6%|6         |   393B / 6.35kB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/Ron00769/jigsaw_binary_base_language_head/commit/f0943df2238da610e30de5ea3612ede2288771e4', commit_message='Upload folder using huggingface_hub', commit_description='', oid='f0943df2238da610e30de5ea3612ede2288771e4', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Ron00769/jigsaw_binary_base_language_head', endpoint='https://huggingface.co', repo_type='model', repo_id='Ron00769/jigsaw_binary_base_language_head'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Create the repository\n",
    "repo_id=\"Ron00769/jigsaw_binary_base_language_head\"\n",
    "create_repo(\n",
    "    repo_id=repo_id,\n",
    "    repo_type=\"model\",\n",
    "    private=False,  # Set to True if you want it private\n",
    "    exist_ok=True   # Won't error if repo already exists\n",
    ")\n",
    "\n",
    "# Step 2: Upload the folder\n",
    "api = HfApi()\n",
    "api.upload_folder(\n",
    "    folder_path=checkpoint,\n",
    "    repo_id=repo_id,\n",
    "    repo_type=\"model\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "Kg_q-rWv1ANn",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/entropy</td><td>‚ñÅ‚ñÜ‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÖ</td></tr><tr><td>eval/loss</td><td>‚ñà‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ</td></tr><tr><td>eval/mean_token_accuracy</td><td>‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà</td></tr><tr><td>eval/num_tokens</td><td>‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà</td></tr><tr><td>eval/runtime</td><td>‚ñÅ‚ñÅ‚ñà‚ñÇ‚ñÖ‚ñÉ‚ñÑ‚ñÜ‚ñÉ‚ñÅ</td></tr><tr><td>eval/samples_per_second</td><td>‚ñà‚ñà‚ñÅ‚ñá‚ñÑ‚ñÜ‚ñÖ‚ñÉ‚ñÖ‚ñà</td></tr><tr><td>eval/steps_per_second</td><td>‚ñà‚ñà‚ñÅ‚ñá‚ñÑ‚ñÜ‚ñÖ‚ñÉ‚ñÖ‚ñà</td></tr><tr><td>train/entropy</td><td>‚ñà‚ñÅ‚ñÉ‚ñÇ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/epoch</td><td>‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>train/global_step</td><td>‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>+5</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/entropy</td><td>2.4311</td></tr><tr><td>eval/loss</td><td>0.27755</td></tr><tr><td>eval/mean_token_accuracy</td><td>0.8774</td></tr><tr><td>eval/num_tokens</td><td>327473</td></tr><tr><td>eval/runtime</td><td>4.3882</td></tr><tr><td>eval/samples_per_second</td><td>46.26</td></tr><tr><td>eval/steps_per_second</td><td>5.925</td></tr><tr><td>total_flos</td><td>6557102325826560.0</td></tr><tr><td>train/entropy</td><td>2.45798</td></tr><tr><td>train/epoch</td><td>2</td></tr><tr><td>+10</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">jigsaw_exp_lmh_gemma_base</strong> at: <a href='https://wandb.ai/ronchaudhuri29-the-university-of-texas-at-dallas/jigsaw_language_head_2025/runs/nzmr0oea' target=\"_blank\">https://wandb.ai/ronchaudhuri29-the-university-of-texas-at-dallas/jigsaw_language_head_2025/runs/nzmr0oea</a><br> View project at: <a href='https://wandb.ai/ronchaudhuri29-the-university-of-texas-at-dallas/jigsaw_language_head_2025' target=\"_blank\">https://wandb.ai/ronchaudhuri29-the-university-of-texas-at-dallas/jigsaw_language_head_2025</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251103_014835-nzmr0oea/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
